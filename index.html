<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="keywords" content="Artificial intelligence, discourse, philosophy of science, religion, materiality">
        <title>Anthropomorphization of Artificial Intelligence</title>
        <style>
            body {
                background: rgb(244, 236, 216);
            }
            .content {
                margin: auto;
                text-align: justify;
                width: 35em;
            }
            a {
                color: black;
            }
            h1 {
                text-align: left;
            }
            h5 {
                display: inline;
                padding-right: 1em
            }
            p {
                text-indent: 1em;
            }
            dt {
                float: left;
                min-width: 1.75em;
                text-align: right;
                padding-right: 0.75em;
                font-weight: bold;
            }
            dd {
                margin-left: 2.75em;
                padding-bottom: 0.25em;
            }
            dd p {
                padding-top: 0em;
            }
            .title-block {
                width: 100%;
                text-align: center
            }
            .title-block p {
                margin: 0px
            }
            .compact-block p {
                margin-top: 0px;
                margin-bottom: 0px
            }
            .no-breaks {
                white-space: nowrap;
            }
            .quote {
                margin-top: 1em;
                margin-bottom: 1em;
                text-align: left;
                font-style: italic;
            }
            .quote .author {
                margin-top: 1em;
                text-align: right;
                font-size: small;
            }
            .footnote {
                margin-top: 1em;
            }
        </style>
    </head>
    <body>
        <div class="content">
        <h1>Anthropomorphization of Artificial Intelligence</h1>
        <p>by Tomáš Kopeček</p>
        <p><i>Brno 2015</i></p>
        <h2>Annotation</h2>

        <p>
        Artifical intelligence is becoming topic in scientific and more and more
        in public space as well. From the beginning it is followed by questions
        which outreach ordinary scientific discussion in terms of Kuhn's normal
        science. Is creating of human-like artificial intelligence moral? Will
        it replace mankind? Is existence of such being even possible if it has
        no soul? Should it have right to vote? Most of this discussion is
        influenced by many effects from position of science, religious stances
        or political goals and not last in the line materiality of engineering
        work. On the second side it has no impact only in scientific world, but
        also in its neighbourhood and whole society in forms of law or in
        formulation of public fears or <q>power</q> struggle of science
        and religion.
        </p>

        <p>
        Topic is slightly researched by sociological, philosophical and
        juridical literature. I'll try to show overview of sociologically
        relevant aspects of this field. In opposite I'll not deal with topics
        which are clearly technical. Methodologically it will be horizontal
        survey which is rooted in different philosophical-sociological
        approaches from Bourdieu's theory of fields through Latour's view on
        materiality to Habermas' theory of communication. Text identifies four
        basic narratives of AI discourse (scientific, religious, securitization
        and artistic) with whose will be illustrating particular topics.
        </p>

        <h2>Keywords</h2>
        <p>
        Artificial intelligence, discourse, philosophy of science, religion,
        materiality
        </p>


        <h2>Table of contents</h2>
        <div class="toc">
            <ol>
                <li>
                    <a href="#auto-1">Introduction</a>
                    <ol>
                        <li><a href="#auto-2">Why</a></li>
                        <li><a href="#auto-3">What</a></li>
                        <li><a href="#auto-4">From Where</a></li>
                        <li><a href="#auto-5">Through What</a></li>
                    </ol>
                </li>
                <li>
                    <a href="#auto-6">Narratives</a>
                    <ol>
                        <li>
                            <a href="#auto-7">Story of Science</a>
                            <ol>
                                <li><a href="#auto-8">Scientific Version of History</a>
                                    <ol>
                                        <li><a href="#auto-9">Philosophy</a>
                                            <ol>
                                                <li><a href="#auto-10">Mission</a></li>
                                                <li><a href="#auto-11">Ethics</a></li>
                                                <li><a href="#auto-12">Philosophy strikes back</a></li>
                                            </ol>
                                        </li>
                                        <li><a href="#auto-13">Materiality</a></li>
                                        <li><a href="#auto-14">Rules of a Field</a></li>
                                    </ol>
                                </li>
                                <li><a href="#auto-15">Discursive Construction of AI</a>
                                    <ol>
                                        <li><a href="#auto-16">Case: Turing</a></li>
                                        <li><a href="#auto-17">Evolution</a></li>
                                    </ol>
                                </li>
                            </ol>
                        </li>
                        <li><a href="#auto-18">Story of Religion</a></li>
                        <li><a href="#auto-19">Story of Alchemy</a></li>
                        <li><a href="#auto-20">Story of Securitization</a></li>
                        <li><a href="#auto-21">Story of Art</a></li>
                    </ol>
                </li>
                <li><a href="#auto-">Conclusion</a></li>
                <li><a href="#auto-">Bibliography</a></li>
            </ol>
        </div>
        <h2>Disclaimer</h2>
        <p>
            This is non-edited long form of final
            <a href="https://is.muni.cz/th/ydcqb/"> short version </a>.
            There are a few reasons to publish it here in this format. Firstly,
            there was some additional research which didn't fit into the shortened version.
            Secondly, it is easier to read it here. Thirdly, original data store distorted
            resulting PDF, so many readers are not able to correctly display it.
            (better file <a href="https://github.com/tkopecek/aianthropomorphization/blob/gh-pages/short.pdf">here</a>).
            It is published late, but better now then never. If there are any typos,
            factual errors, etc. feel free to file a github issue. Otherwise,
            I'm not planning to update the text.
        </p>
        <hr>
        <h1 id="auto-1">1 Introduction </h1>
        <div class="quote">
            Everyone takes the limits of his own vision for the limits of the world.
            <div class="author">
                <a href="#bib-schopenhauer_studies_2008">Arthur Schopenhauer</a>
            </div>
        </div>
        <div class="quote">
            <p>
            <q>You may read <em>Principia Mathematica</em>
                without finding discourse of souls, spirits, cogitation, or
                what-have-you,</q> said Isaac. <q>
                It is about planets, forces, gravity, and geometry. I do not address, and
                certainly do not pretend to solve, the riddles that so confounded Monsieur
                Descartes. Why should we attempt to frame hypotheses about such matters?</q>
            </p>

            <p>
            <q>Because if you do not, Sir Isaac, others, of less brilliance, will; and
                they will frame the wrong ones. </q>
            </p>
            <div class="author">
                <a href="#bib-stephenson_system_2005">Neal Stephenson</a>
            </div>
        </div>

        <h2 id="auto-2">1 Why</h2>
        <p>
        Three ugly words in title of something what should not be a research
        work but a bachelor thesis. That needs some kind of explanation. Let's
        cast na&iuml;ve question: <q>Why study something like Artificial
            Intelligence (AI) (something which doesn't exist) from sociological
            stance?</q> and similarly na&iuml;ve answer follows: <q>Because
            it matters (and sociology deals with things which <q>don't
                exist</q>.</q> Now we have to see it more broadly.
        </p>
        <p>
        At first here comes AI. It is a thin stream which is born in twentieth
        century (but it has in many points quite ancient roots as we will see
        later) and is slowly gaining momentum to these days. Now AI concept is
        something which almost everyone is more or less familiar with.
        </p>
        <p>
        From early fifties when Alan Turing comes with his famous
        <a href="#bib-turing_computing_1950">Imitation game</a> through all
        buzz of excited sixties when
        Marvin Minsky becomes a new apostle of AI religion until these days when
        there is no month without some <q>progressive</q> news from the field.
        </p>
        <p>
        Story of AI is not only about technical expertise, but also encapsulates
        many others and a lot of them are sociologically relevant. Permanent
        struggle of science and religion stages another battlefield here which
        ironically shows more religious zeal on side of (positivist) science.
        Politics also become involved as there is a few forces which has to
        emancipate themselves through permeating law systems with AI-related
        concepts ending even with <em>Charter of Fundamental Rights and Freedoms</em> AI amendments.
        </p>
        <p>
        There is still one word left &mdash; anthropomorphization. There is a
        reason, in fact more of them, why most work related to AI is thinking
        about it as about a human-compatible creature. We will see that it is
        quite problematic &mdash; from point of <q>creature</q> to
        <q>human-compatible</q> concepts. There are some reasons why experts
        expects it to be alike, but there are also not a few problems which such
        thinking raises.
        </p>

        <h2 id="auto-3">2 What</h2>
        <p>
        Let's dive into main lines of thinking about AI and look to which social
        and cultural aspects played and still plays important roles here. Whole
        AI sector even if it looks like ultra-rationalist and firmly rooted in
        modern positivism is full of contradictions. We will go so far that in
        extreme position we will describe it as a religious project which builds
        on Judeo-Christian roots touched by hermetism and gnosticism. AI story
        is becoming part of a much larger cultural stream from Enkidu through
        hermetic homunculi, golems and entering modern era via Mary Shelley's
        <q><a href="#bib-shelley_frankenstein;_2012">Modern Prometheus</a></q> &mdash; Frankenstein's monster.
        We will see how is AI discursively constructed, how this
        construct backfires to its authors and how still non-existent (strong)
        AI is changing existing world already.
        </p>
        <p>
        Whole discourse on AI is quite complex and for purposes of this work
        I've to tear out just few stripes. To keep (not so false) complex system
        idea I'm going to not choose only one line but few narratives whose
        should serve as a base for limited horizontal overview of the field.
        Thus, we will go through scientific, religious, securitization and
        artistic stories. In the end it should draw picture how such detached
        topic as AI for most of population is can change and changes our
        everyday world.
        </p>

        <h2 id="auto-4">3 From Where </h2>
        <p>
        Let's call this section <q>Section of clarifications</q>. First
        clarification is to say, from where I'm coming. I'm not born-and-raised
        sociologist. My epistemo-ontological origins lies near to the enemy. In
        fact, I'm coming directly from the eye of the storm &mdash; theoretical
        informatics, more specifically from mathematical linguistics branch
        directly building on Wittgenstein, Chomsky and mathematical intuitionism<sup><a id="footnote-1-back" href="#footnote-1">1</a></sup>
        speaking with <q>Leibniz-like</q> philosophical language. On the
        other side I've to deal with quite different languages like theological
        philosophy of <a href="#bib-de_chardin_mans_1966">Teilhard de Chardin</a>.
        </p>
        <p>
        We are both speaking about areas somehow related to AI problematic, but
        for many people each of these languages is incomprehensible. I wanted
        quickly illustrate how wide is the stream of thinking which I have to
        grasp. But instead of it I see that I'm falling to one of the modern
        traps &mdash; building dichotomy. Mathematics vs. philosophy, 2008 vs.
        1949 So I'll try to fix it a bit. Let's add some new axes and let these
        two extremes slowly melt into the amalgam of (post)modernity.
        </p>

        <h2 id="auto-5">4 Through What </h2>
        <p>
        From the point of philosophy I will be mainly operating on one side with
        Leibniz, Kant and Nietzsche &mdash; in topics related to ethics and
        epistemology. Reasons for that will be given in section on materiality.
        On the other side there will be Wittgenstein, Habermas
        [<a href="#bib-habermas_between_2008">Habermas and Cronin, 2008</a>,
        <a href="#bib-habermas_future_2003">Habermas, 2003</a>,
        <a href="#bib-habermas_habermas_1996">Habermas and Outhwaite, 1996</a>],
        <a href="#bib-alexander_structure_1989">Alexander</a> useful in
        area of meaning construction. To the mix will be added some authors from
        the science of philosophy arena which will be touching the topic from
        more angles as it is the only reflective apparatus which could be used
        to reflect on scientific dimension of AI.
        </p>
        <p>
        In sociology I'm quite influenced by Latour's notion of networks
        [<a href="#bib-latour_reassembling_2007">Latour, 2007</a>,
        <a href="#bib-latour_we_1991">Latour and Porter, 1991</a>],
        nevertheless it will be used in somehow <em>na&iuml;ve</em> way, as this
        is not research work and there are only tiny resources dedicated to AI
        topic. It will be set in contrast with Alexander's critic expanded by
        <a href="#bib-hodder_entangled:_2012">Hodder</a> mostly concerning the materiality
        issues. Of course, we can't evade classical sociologists as Marx,
        Durkheim and Weber mainly through their critics or followers. Guide to
        the religious aspects is Geraci [<a href="#bib-geraci_apocalyptic_2008">Geraci, 2008</a>, <a href="#bib-geraci_novel_2014">Geraci,
            2014</a>, <a href="#bib-geraci_robots_2007">Geraci, 2007</a>, <a href="#bib-geraci_there_2011">Geraci, 2011</a>]
        </p>
        <p>
        Of course there will be a lot of references to insider scholars and
        practitioners dealing with AI and related fields such as
        <a href="#bib-turing_computing_1950">Alan Turing</a>,
        <a href="#bib-minsky_perceptrons:_1972">Marvin Minsky</a>,
        Hans Moravec [<a href="#bib-moravec_mind_1988">Moravec, 1988</a>,
        <a href="#bib-moravec_universal_1991">Moravec, 1991</a>] or Ray Kurzweil
        [<a href="#bib-kurzweil_dont_2014">Kurzweil, 2014</a>,
        <a href="#bib-kurzweil_promise_2001">Kurzweil, 2001</a>,
        <a href="#bib-kurzweil_singularity_2005">Kurzweil, 2005</a>].
        </p>
        <p>
        There is no definitive methodology I'll be using. It could be some loss
        and on the other side some highlight of the work. So, if I've noted that
        I'll add few more axes to distorted image I'll be adding also
        sociological and philosophical approaches which should allow us to see
        more holistic picture.
        </p>
        <p>
        Such mix of schools will provide, I believe, some insight into the field
        with wider scope than choosing one limited approach which would require
        some speculations and would be more appropriate for empiric research
        such is not intended part of this bachelor's thesis. From the same
        reason is not any specific method of inquiry used.
        </p>

        <h1 id="auto-6">2 Narratives </h1>

        <h2 id="auto-7">1 Story of Science </h2>
        <div class="quote">
            The chance of the quantum theoretician is not the ethical freedom of the Augustinian.
            <div class="author"><a href="bib-kurzweil_singularity_2005">Ray Kurzweil</a></div>
        </div>

        <div class="quote">
            For lack of better terms, we call ourselves sociologists, historians, economists,
            political scientists, philosophers or anthropologists. But to these venerable
            disciplinary labels we always add a qualifier: <q>of science and technology</q>.
            <q>Science studies</q>, as Angloamericans call it, or <q>science, technology and society</q>.
            <div class="author"><a href="bib-latour_we_1991">Bruno Latour</a></div>
        </div>

        <p>
        Long story short. Science and in this case hard science is minefield of
        epistomologic and ontologic misunderstandings. And similar dangers lies
        on the sociology side. We will slowly navigate through it and also
        probably hit some hidden mines.
        </p>
        <p>
        Narrative is probably most-known in public discourse. It is quite logic
        (even if word <q>logic</q> will be soon problematized) as it is related
        to origin of actors which are involved in AI development. In first place
        this narrative is <q>natural</q> for them and not in last it provides
        benefits. From the legitimization by science or possibility to use
        scientist status to utter new <q>facts</q>.
        </p>

        <h3 id="auto-8">1.1 Scientific Version of History </h3>
        <p>
        Let's dive into history of AI as initial framing. As this is scientific
        story, I ignore more mystical roots and to demarcate some starting point
        I deliberately choose Leibniz. Some authors (<a href="#bib-pratt_thinking_1987">Pratt</a>,
        <a href="#bib-churchland_matter_2001">Churchland</a>) puts him as grandfather of AI even if it sounds quite exaggerating.
        <a href="#bib-eco_search_1995">Umberto Eco</a>] takes different approach and stays more with what Leibniz really
        formulated and thrived for &mdash; which is universal philosophical
        language
        <em>characteristica universalis</em>
        designed to describe everything in the universe. This idea is coming in
        the second half of seventeenth century. What is new with Leibniz
        approach is <q>scientific</q> approach. He is leaving searching mode of
        original God language and moving to <q>modern</q> way of constructive
        science. His vague design of philosophical language has heavily
        influenced even <a href="#bib-rescher_philosophical_2011">Kurt G&ouml;del</a>. G&ouml;del himself is second big foundation stone of modern
        computation<sup><a id="footnote-2-back" href="#footnote-2">2</a></sup>. On the technical side there is Pascal, Charles Babbage and Ada
        Lovelace (famous <em>Enchantress of Numbers</em>
        which we will see again later in religious pantheon of AI cult in
        <em>(<a href="#auto-15">Discursive Construction of AI</a>)</em>) on their road to mechanical computer.
        <sup><a id="footnote-3-back" href="#footnote-3">3</a></sup>
        </p>
        <p>
        Alan Turing is finally the person which has brought this philosophical,
        mathematical and engineering streams of thinking to its
        <a href="#bib-muggleton_alan_2014">climax</a> and started the AI revolution.
        In year 1950 he publishes
        fundamental text with which contemporary scientific world still has not
        settled in satisfactory way. In <em><a href="#bib-turing_computing_1950">Computing Machinery and
            Intelligence</a></em> he creates famous
        <em>Imitation Game</em> where he proposes <q>test</q> (which is
        immediately named after him) which should verify if computer (machine,
        more generally) can think.
        </p>
        <p>
        Noam Chomsky's
        <em><a href="#bib-chomsky_syntactic_2002">Syntactic Structures</a></em>
        are going to print in 1957. Following Wittgenstein's linguistic turn
        and merging it with formal logic, Chomsky once more opens door for
        computers to metaphysics. His essential concept of language classes is
        inherently connected to problems of computability and computation theory
        of brain modelling. Engineers got one more bullet to their crucial
        argument that brain
        <em>is</em>
        machine. When it got linked with
        <a href="#bib-turing_computable_1936">Turing machine limits</a> and
        <a href="#bib-kleene_introduction_1952">Church-Turing thesis</a> It based almost
        unbreakable foundations<sup><a id="footnote-4-back" href="#footnote-4">4</a></sup>.
        Research in physiology and biology in the same time adds to the theory
        of AI. It is probably not an accident that year before publication is
        first
        <em>Dartmouth Project<sup><a id="footnote-5-back" href="#footnote-5">5</a></sup></em>
        run, where the term <q>Artificial Intelligence</q> is coined (To what
        AI is and how it became term of itself is covered in
        <em><a href="#auto-15">Discursive Construction of AI</a></em>.
        This is the point where AI is definitively connected with computers
        and computational theory of mind.
        </p>
        <p>
        Pragmatism, as one of the post-positivist ways out, allows opening of
        full scale of differently educated theories, which further allows
        building model of human behaviour, brain and human (or
        <q>human-like</q>) manifests. Idea of so-called <q>Rule-based
        reasoning</q> as an inference model for human behaviour is born. It builds
        on same thesis as <em>homo economicus</em>. Man is driven by rational
        rules. It is emerging in the time when
        <a href="#bib-skinner_about_1976">Skinner's radical behaviourism</a> is going to be one of the leading schools
        of USA's psychology science. This paradigm evolves with psychology
        through Dennett's <em><a href="#bib-dennett_consciousness_1992">Computational Theory of Mind</a></em> until contemporary trends in <em>Computational Ethics</em>
        [<a href="#bib-allen_prolegomena_2000">Allen et al., 2000</a>,
         <a href="#bib-torrance_ethics_2008">Torrance, 2008</a>,
         <a href="#bib-leuenberger_universal_2014">Leuenberger, 2014</a>] and finally
         <em>Model-based Reasoning</em> as convolution with neuroscience
        [<a href="#bib-thagard_brain_2010">Thagard, 2010</a>,
         <a href="#bib-blank_intervention_2013">Blank, 2013</a>,
         <a href="#bib-jones_resolving_2003">Jones, 2003</a>].
         Long-time paradigm shift is from constructing
         AIs from scratch to design of learning machines which can evolve on
         their own [<a href="#bib-cristianini_current_2014">Cristianini, 2014</a>, <a href="#bib-velik_quo_2010">Velik, 2010</a>].
        </p>

        <h4 id="auto-9"><a id="sec:philosophy"></a>1.1.1 Philosophy </h4>
        <p>
        The philosophy approaches which are utilized by AI scientists, could be
        helpful to understand what drives and what also limits them. Philosophy
        in AI is divided to few quite distinct areas. First one is approach to
        science itself. What is the science, what is its purpose and how
        reflectively they look to it. Second (and definitely being most
        explored) field is ethics. And the last one is relationship between
        science and lived world.
        </p>
        <p>
        In population and especially in academics there is present idea, that
        technology is not a field where theory of science is reflected well. If
        it is true, false or irrelevant is not of our concern now. I'll look to
        points where sociologists and philosophers looks upon AI science and how
        science builds its own philosophical foundations.
        </p>
        <p>
        There is a tradition from Plato and Aristotle, through Leibniz and
        Newton to Russell which is slowly taking mathematics to its knees and
        forcing it to reflect upon itself. Especially Whitehead's and Russell's
        <em><a href="#bib-whitehead_principia_1963">Principia Mathematica</a></em> (of course pointing to Newton's
            <em><a href="#bib-newton_philosophiae_1723">Philosophi&aelig; Naturalis Principia Mathematica</a></em> has
        shown problems which are hidden in the base of math in the modern light.
        In the early twentieth century schools divided according to
        epistemological and ontological explanations to three basic branches:
        formalism, intuitionism and logicism. Mainly discussions of
        epistemological qualities directly influenced AI research. Floridi
        mentions that in year 1964 <q>philosophy of AI had already produced
            more than a thousand articles</q> [<a href="#bib-floridi_open_2004">Floridi, 2004</a>,
        p. 566] which is stunning compared to the fact that
        in that time computers were able to solve limited set of word
        mathematical <a href="#bib-bobrow_natural_1964">problems</a> which is quite far
        from what we imagine under word AI.
        </p>
        <a id="auto-10"></a>
        <h5>Mission </h5>
        <p>
        If we look to almost random paper, which is not purely technical, we
        will see some similar features. Typically, it is self-confidence that
        what science is doing here is important and even <q>the mission</q> of
        mankind. Creation of AI is inevitable. <q>The Singularity denotes an
        event that will take place in the material world, the inevitable next
        step in the evolutionary process that started with biological evolution
        and has extended through human-directed technological evolution.</q>
        [<a href="#bib-kurzweil_singularity_2005">Kurzweil, 2005</a>]
        <sup><a id="footnote-6-back" href="#footnote-6">6</a></sup>
        Background could be different &mdash; here Kurzweil reasons with
        evolution, otherwise it could be simple eternal value of knowledge like
        here: <q>Artificial life is foremost a scientific rather than an
            engineering endeavor.</q> [<a href="#bib-bedau_open_2000">Bedau et al., 2000</a>] &mdash; ignore engineers, do science no matter what.
        </p>
        <p>
        <a id="auto-11"></a>
        <h5>Ethics </h5>
        <p>
            There is a lot of open questions regarding to ethics. We investigate
            few here and more later in <em><a href="#auto-18">Story of Religion</a></em> which is
            definitely more concerned with it.
        </p>
        <p>
        Questions being asked here are about what makes AI living, creature,
        human or superhuman. They are important in ethical part simply because
        they define how we will behave to and with AIs. Typical question which
        haunts the field is question if AIs are genuine or if they just
        <q><a href="#bib-bickhard_robot_2014">simulate</a></q>. Searle's Chinese room
        dilemma redefined this typical western dichotomy, where we can see
        Alexander's binary cultural codes. It is not important here if AI is
        compatible or indistinguishable from human. Important is what's its
        <a href="#bib-levine_sociality_2014">ontology</a>. Another dichotomy is put if there
        is some <a href="#bib-laukyte_artificial_2014">personhood</a> or not. Binary division
        is also seen if AI needs to have <a href="#bib-megill_emotion_2014">emotions</a>.
        These few examples shows that general tendency is to grasp some specific
        concepts where almost all of them are taken from (philosophical) human
        traits and as such are not definable and try to find if they are
        applicable to AIs. These concepts can be defined relationally as
        human-only and as such is futile to try to map them to AIs. It mostly
        creates only false contradictions as there is no objective position from
        which it can be evaluated.
        </p>
        <p>
        Final comment about this topic is reflection of these anhropomorphic
        terms via Coeckelbergh: <q>Verbeek's turn to what things
            <em>do</em>
            remedies this problem, but his conclusion that we therefore should talk
            about <q>moral</q> artefacts or the <q>morality of things</q> goes at
            the cost of diluting the anthropocentric meaning we like to give to the
            terms <q>moral</q> and <q>morality</q>.</q> [<a href="#bib-coeckelbergh_virtual_2009">Coeckelbergh, 2009</a>, p. 183]
        <sup><a id="footnote-7-back" href="#footnote-7">7</a></sup>
        We see here, that whole topic of ethical things is quite problematic in
        binary view. There are two ways out &mdash; to stop thinking in
        dichotomy and adopt non-discriminating approaches, which is sometimes
        proposed, mostly inspired by <a href="#bib-adam_ethics_2008">Latour</a>
        or throw away this type of morality at all and stays on human-only
        level.
        </p>

        <a id="auto-12"></a>
        <h5>Philosophy strikes back</h5>
        <p>

            <q>The new technologies make a public discourse on the right
                understanding of cultural forms of life in general an urgent matter.
                And philosophers no longer have any good reasons for leaving such a
                dispute to biologists and engineers intoxicated by science
                fiction.</q> [<a href="#bib-habermas_future_2003">Habermas, 2003</a>, p. 15]
            as we see here, Habermas has quite clear view on the problem, that
            ethical and philosophical decisions are being made by
            <q>unqualified</q> engineers. Many philosophers are disturbed that
            tunnelled view of engineers should be contemplating about future of
            mankind. It is disputable if these reactions are relevant and if
            philosophy is reflective enough upon itself. There is a lot of
            opinions which says that opposite is true. When we are talking about
            Habermas we can point e.g. Latour's reaction on
            him. In [<a href="#bib-latour_we_1991">Latour and Porter, 1991</a>, p. 60]
            he makes an attack based on idea, that Habermas intention is to defend
            modernity. According to Latour he denies postmodernity's right to
            existence (he categorizes him as <q>pre-postmodern</q>). In such
            situation is hard to believe that philosophy as a field has some
            <q>superior</q> rights to speak about AI ethics. We also see examples
            (especially Searle) which more defends their place in the postmodern
            science than to use rational arguments. In case of Habermas it is
            quite ridiculous compared with his theory of communicative action. Of
            course, only at first sight. We see, what he tries to communicate here
            <q>philosophy is more special than engineering</q>.
        </p>
        <p>
        Nevertheless, Habermas slowly leads us to chapter about religiosity,
        with which philosophy is very closely related. <q>The scientistic
            belief in a science which will one day not only supplement, but replace
            the self-understanding of actors as persons by an objectivating
            self-description is not science, but bad philosophy.</q> [<a href="#bib-habermas_future_2003">Habermas,
            2003</a>, p. 108] It is obviously another attack on
        incompetent engineers. If we ignore the tone and get base message, we've
        to agree. It is belief in science. It is not rationally defensible
        position. Habermas further explains that science is mostly performed as
        a religion. It is aligned with late Berger's diversion from
        secularization thesis. Society is no more secular. In this postsecular
        society still stays a lot of endemic places which are not aware of it.
        One of these is (western) science itself. Ironically, science which has
        proposed concept of postsecularism is disturbed by another postmodern
        attack on its primacy. Most of science (in this case hard-science) tend
        to ignore this interpretation and stays in secular phase, which is from
        outside-view interpreted as a religious institution [<a href="#bib-evans_faith_2014">Evans,
            2014</a>, <a href="#bib-knight_human_2010">Knight and Murphy, 2010</a>]. In such paradigm makes
        sense to communicate with science but definitely not to adhere to its
        ontological meanings.
        </p>
        <p>
        Another example of fear from mathematical-naturalistic hegemony is shown
        in Floridi's <a href="#bib-floridi_open_2004">paper</a>. Informational theory of
        cognition and human behaviour and its concepts are in his view so
        powerful, that they ultimately dodge almost every criticism.
        <q>Informational concepts are so powerful that, given the right
        level of abstraction (LoA) (Floridi and Sanders 2004), anything can be
        presented as an information system, from a building to a volcano, from a
        forest to a dinner, from a brain to a company, and any process can be
        simulated informationally &mdash; heating, flying, and knitting.</q>
        [<a href="#bib-floridi_open_2004">Floridi, 2004</a>, p. 566] He concludes
        that in such case this theory lies in the realm of dogma. Such science
        is no Popper's science for Floridi. It is something what is pragmatic
        engineering but not contestable science. They have to leave that
        paradigm which on the one side proclaims G&ouml;del's paradox and in the
        same moment does not want to measure itself by it.
        </p>
        <p>
        Why I'm elaborating on these issues is my attempt to show that
        independently on real topic of discussion, AI creates arena for fight of
        two scientific fields. In <a href="#bib-bourdieu_distinction:_1984">Bourdieu's</a> sense we see on one side hard-science with its questionable
        <q>objective truth</q>
        <sup><a id="footnote-8-back" href="#footnote-8">8</a></sup>
        and on the other side philosophy which pulls itself out of science to
        higher-ground of patronizing referee position <q>above science</q>.
        Fight is staged via standard <q>scientific</q> means such as papers and
        also out of the field, legitimizing itself and fight for public.
        </p>

        <h4 id="auto-13"><a id="sec:materiality"></a>1.1.2 Materiality </h4>
        <p>
        <q>The political task starts up again, at a new cost. It has been
            necessary to modify the fabric of our collectives from top to bottom in
            order to absorb the citizen of the eighteenth century and the worker of
            the nineteenth. We shall have to transform ourselves just as thoroughly
            in order to make room, today, for the nonhumans created by science and
            technology.</q> [<a href="#bib-latour_we_1991">Latour and Porter, 1991</a>, p. 136]
        This Latour's idea is one of the central problems of previously
        mentioned <em>Computation Ethics</em>. Ideas on which this concept
        builds are not uninteresting. We can see how process of theory choosing
        is driven by a) hegemonic (informatics) discourse (more in <em><a  href="#auto-15">Discursive Construction of AI</a></em>
         and b) technical possibilities. Especially second
        aspect is interesting from the point-of-view of sociology and even more
        from latourian perspective. We will see how these (basic) questions are
        practically without any freedom determined by technology which dictates
        its own rules. View on if what means <q>ethical agent</q> is basal for
        such discussion.
        </p>
        <p>
        To speak with language of the field, scientists distinguishes between
        <em>ethical-impact agents</em>,
        <em>implicit ethical agents</em>,
        <em>explicit ethical agents</em> and
        <em>full ethical agents</em>
        (like in [<a href="#bib-tonkens_challenge_2009">Tonkens, 2009</a>,
        <a href="#bib-debaets_can_2014">DeBaets, 2014</a>]).
        <sup><a id="footnote-9-back" href="#footnote-9">9</a></sup>
        Agents would lead us to Latour's concept of agency. In fact a lot of AI
        ethicists are acquainted with it and are using it in
        <a href="#bib-coeckelbergh_virtual_2009">some way</a>.
         The problem of agency concept is similar to one which is once and
        again hit by Latour's disciples and critics &mdash; it sounds too
        anthropomorphic. It no more matters that it is not
        <sup><a id="footnote-10-back" href="#footnote-10">10</a></sup>,
        the problem is that is often perceived as such. In this concrete case
        the first two types of agency (ethical-impact and implicit) are
        connected more to things and latter two with humans (AIs, creatures,
        &hellip;).
        </p>
        <p>
        While ethical-impact agent is something what has no <q>real</q> agency,
        it can be used in ethically-relevant way. Knife has no ethical impact
        until it is used to kill. Implicit ethical agent has some possibility to
        influence reality in such way. Airbag in car is designed to serve
        ethical purpose and it can be activated in right moment. Technically it
        is designed to be <q>moral</q> agent without possibility to choose
        immoral option. Explicit ethical agent has options to do morally
        relevant actions in both directions. Autonomous military drone can
        choose about target or not to shoot at all [<a href="#bib-sparrow_killer_2007">Sparrow, 2007</a>,
        <a href="#bib-hallevy_when_2013">Hallevy, 2013</a>]. Full ethical agent has furthermore all
        other options which explicit ethical agent lacks. Simply, nowadays only
        full ethical agent is human.
        </p>
        <p>
        Now back to previous claim &mdash; we <q>naturally</q> feel that the
        latter two are <q>more human</q>. They describe some <q>creature</q>
        which has options to choose relevant action. Both of them have
        <q>free will</q> in some way. This feeling is supported by human-like
        word <q>agent</q>. This discourse brings us more to anthropomorphic
        representation than before. <q>Importantly, new artificial actors do
        not enter the stage from nowhere. We design them. We can give them the
        mask, the appearance we want. Since we love ourselves as humans, it is
        very likely that we will give them our own mask. Or the mask of the
        animals that remind us of our own, human infants.</q> says <a href="#bib-coeckelbergh_virtual_2009">Coeckelbergh</a> and it also becomes one of problems in the
        field.
        </p>
        <p>
        Generally we can see here (and whole ethics of AI is) tendency to
        interpret such complex machines in terms related to social world.
        Sharkey quotes psychological <a href="#bib-sharkey_artificial_2006">study</a>
        which studied people evaluating other people (and in which
        case they were more positive if evaluated person was present) compared
        to people evaluating computers (in which case they were more positive if
        computer was present). Simply people treated computers like persons in
        this case. This has to fall in section about materiality as these
        <q>things</q> directly change way how we think and behave only by their
        mere presence. <q>Indeed we are often quite willing to ascribe
            intentionality to much less human-like things e. g.
            <q>My car doesn't want to start this morning. My computer is
                thinking about it.</q></q> [<a href="#bib-adam_ethics_2008">Adam, 2008</a>, p. 152]
            Such approach leads to problems that human traits are ascribed to
            machines and in the field of ethics it means (as easiest way) that
            human-targeted ethic (as Kant's is) is used on them. Some authors of
            course noted this problem and Adam, which is quoted here, proposes:
            <q>The combination of the arguments of Latour on the attribution of
                agency, even moral agency to things, Dennett's <q>as if</q>
                intentionality, Magnani's moral mediators and Collins' and Kusch's
                delegation of action all lend support to IE as an ethics where things
                have as much place as humans.</q> [<a href="#bib-adam_ethics_2008">Adam, 2008</a>, p. 154 It is reflected by Latour's program: <q>So long
                                                      as humanism is constructed through contrast with the object that has
                                                      been abandoned to epistemology, neither human nor the nonhuman can be
                                                      understood.</q> [<a href="#bib-latour_we_1991">Latour and Porter, 1991</a>, p. 136].
                                                  Adam goes this way, while most of the authors simply ignores it and
                                                  continues with anthropocentric approaches.
        </p>
        <p>
        If ethicists have intention to create AMA (autonomous moral agents) as
        they call their holy grail, they are coming to trap what <q>ethical</q>
        means. If it has to be implemented in machine they have these options:
        a) design ethical model and implement it b) let ethical behaviour emerge
        from AI itself. Mostly from securitization perspective option
        <em>b</em>
        is out of the game as there is no way how to prevent potential damage
        <sup><a id="footnote-11-back" href="#footnote-11">11</a></sup>
        [<a href="#bib-davis_ethical_2015">Davis, 2015</a>]. So, only option
        <em>a</em>
        is relevant. This is the time when ethics hits the wall. <q>Free
        will has to be <q>technologically modelled</q> first, in robot/AI
        design or in imagination, before we can fully work out the philosophical
        difficulties.</q> [<a href="#bib-coeckelbergh_virtual_2009">Coeckelbergh, 2009</a>, p.
        184] It is one of the problems. AI needs free will <q>defined</q> and
        <q>implemented</q>. Only after that there is a possibility to implement
        ethical behaviour. There are tons of proposals how to do that and every
        each of them is limited by technical possibilities. It is not by chance,
        that AI geeks are into Kant. It is simply too tempting to have global
        categorical imperative in AI. It seems to be simplest to program.
        </p>
        <p>
        Now taking bridge to Kant. Andersons states, that <q>Deontic logic's
            formalization of the notions of obligation, permission, and related
            concepts, make it a prime candidate as a basis for machine
            ethics.</q> [<a href="#bib-anderson_status_2007">Anderson and Anderson, 2007</a>, p. 8] and further says that <q>one of the central issues in machine
            ethics is trust and <q>mechanized formal proofs are perhaps the
                single most effective tool at our disposal for establishing
                trust.</q></q> We can easily see here, that parameter for choosing
            ethical theory or principles is not based on anything else than on some
            plausibility (use something which has legitimate status) and it has to
            be algorithmically easily described. When we set such rules, there is
            not many systems which satisfy them. We already limit ethical systems to
            deontic ones and it seems that only Bentham's
            <a href="#bib-anderson_status_2007">utilitarianism</a>
            and Kant's categorical imperative
            [<a href="#bib-tonkens_challenge_2009">Tonkens, 2009</a>,
            <a href="#bib-allen_prolegomena_2000">Allen et al., 2000</a>]. We will see in
            <em>(<a href="#auto-13">Materiality</a>)</em>
            that these systems are not so well thought out for AI and have internal
            contradictions, but they are still top candidates because of their
            compatibility with programming.<sup><a id="footnote-12-back" href="#footnote-12">12</a></sup>
            Other types like <em>virtue ethics</em> have much more technical problems,
             that they are not considered at all or only as a supplement to one of the
              <a href="#bib-wallach_machine_2007">previous</a>.
        </p>
        <p>
        There is of course a lot of another material limitations and questions
        of related ethics, such as <a href="#bib-vargas_advocating_2011">memory issues</a>,
        <a href="#bib-barandiaran_norm-establishing_2014">biologically-derived ethics</a>,
        <a href="#bib-cole_automated_2012">human comfort</a> or actual real-world problems
        as reappearance of <q>trolley problems</q><sup><a id="footnote-13-back" href="#footnote-13">13</a></sup>
        with <a href="#bib-bonnefon_autonomous_2015">autonomous cars</a>. Whole field
        of materiality-impacted theory is also linked to
        embodiment and problems of AI with or without body [<a href="#bib-maccormack_posthuman_2012">MacCormack, 2012</a>,
        <a href="#bib-kaur_kant_2013">Kaur, 2013</a>,
        <a href="#bib-seaman_neosentience_2008">Seaman and Rossler, 2008</a>].
        </p>

        <h4 id="auto-14">1.1.3 Rules of a Field </h4>
        <p>
        From <a href="#bib-bourdieu_rules_1996">Bourdieus's</a>, <a href="#bib-bourdieu_distinction:_1984">view</a>, we've to count on field of science. How science and
        especially positivist science is done make very large impact to how AI
        is constructed. Let's make take an example from Velik:
        </p>

        <blockquote>
            <p>
            In 1969, for instance, M. Minsky and S. Papert published their
            famous work on Perceptrons [84] criticizing computational models of
            the nervous system, which showed <q>with unanswerable
            mathematical arguments that such models were incapable of doing
            certain important computations</q> [70]. This killed most
            research in neural computing for the following 15 years. Much later,
            S. Paper admitted in an interview [70]: <q>Yes, there was some                    hostility behind the research reported in Perceptrons &hellip; part
            of the drive came from the fact that funding and research energy was
            dissipated &hellip; money was at stake.</q> In recent times,
            these conditions have turned out to be particularly hard for
            scientists working in Brain-Inspired AI. [<a href="#bib-velik_ai_2012">Velik, 2012</a>,
            p. 44]
            </p>
        </blockquote>
        <p>
        Marvin Minsky &mdash; one of the loudest proponents of AI caused
        so-called <q>AI winter</q> for almost twenty years not only from
        scientific right to critique, but also from political reasons like
        funding. We can't close eyes in front of this. It is likely that if in
        this case Minsky reflected this push, there still have to be many more
        examples when scientists are not able to recognize these non-voluntary
        pressures. Two biggest can be still easily imagined &mdash; military and
        business. Illusion that AI is independent of anything and it is purely
        scientific project is something what discourse builds on, but in the
        same time it is mere illusion.
        </p>
        <p>
        The <q>Pure Science</q> trope is building on its independence, but as
        already Merton noted,
        </p>
        <blockquote>
            <p>
            Science includes disinterestedness as a basic institutional element.
            Disinterestedness is not to be equated with altruism nor interested
            action with egoism. Such equivalencies confuse institutional and
            motivational levels of analysis&hellip; It is rather a distinctive
            pattern of control of a wide range of motives which characterizes
            the behavior of scientists. [<a href="#bib-merton_sociology_1973">Merton, 1973</a>]
            </p>
        </blockquote>
        <p>
        Ethos of scientific truth as goal for itself successfully hides most
        external influences and reifies itself building false legitimization
        base for AI scientists. Typical example where this issue is noted, but
        not reflected properly is in Campa's <a href="#bib-campa_pure_2008">text</a> where he states <q>quest for pure knowledge
            <em>is</em> and <em>can</em> be part of the transhumanism agenda</q>.<sup><a id="footnote-14-back" href="#footnote-14">14</a></sup>
        There is even not much reflection why transhumanism should, or could,
        be part of science at all. Important is that it is somehow compatible
        with Pure science and that means, that it is good.
        </p>

        <h3 id="auto-15"><a id="sec:discourse"></a>1.2 Discursive Construction of AI</h3>
        <p>
        Term itself &mdash; Artificial Intelligence was coined in 1956. Of
        course, there is a long history of how term was chosen and another long
        history how its meaning has been changing until today.
        </p>

        <h4 id="auto-16"><a id="sec:turing"></a>1.2.1 Case: Turing </h4>
        <p>
        <a href="#bib-turing_computing_1950">Imitation Game</a> made a significant impact on
        AI term. I'm not going into deep why Turing did this and did this in
        this exact way. I still would anticipate that he never expected what
        such relatively simple article will do in next hundred years. What was
        so extraordinary with this <q>AI test</q>, that it is still seriously
        considered even if it has quite a lot of methodological flaws (e.g.
         [<a href="#bib-berrar_turing_2013">Berrar et al., 2013</a>]) that renders it
        completely unusable from scientific point of view?
        </p>
        <p>
        Let's start with simple transcription. The crucial question which should
        be answered by proposed test is <q>Can machines think?</q> Human
        interrogator is set to position where he can ask two other
        <q>creatures</q> any question. By investigating answers, reaction
        times, mood, generally whatever he has to decide which of creatures is
        computer and which is human. Turing further sets estimation that in
        fifty years there will be smart-enough machine that human interrogator
        will not be able to guess correctly in more than 70%
        of cases after five-minute interrogation. From present it seems that
        many computers already passed this test as 30%
        threshold is quite low. We know from practical life, that there are many
        people who believe to spambots and even can be forced to do some
        <q>self-destructive action' like sending money to these virtual
            identities.</q>
        </p>
        <p>
        What probably makes paper special in that time is next section with
        responses to <em>anticipated</em> objections. It is noteworthy to
        emphasize word anticipated as selection of these question shows us state
        of the time. And we will see, that most of them defined debate for
        almost hundred years now. There is nine of them and first is
        <q>Theological Objection</q>. We're set in Great Britain, 1950. What
        engineer selects as an objection to AI? Religion and Immortality. It is
        not question about possibility of thinking but about Right of Creation.
        We will investigate this obsession in <em><a href="#auto-18">Story of Religion</a></em> and
        <em><a href="#auto-19">Story of Alchemy</a></em>.
        </p>
        <p>
        Next argument is about dangerousness of such machines and it prefigures
        <em><a href="#auto-20">Story of Securitization</a></em>. Mathematical objection is mentioning the
        superiority of human over machine by <em>defining</em> it as such.
        Interrogator is asking machine logical paradox. Machine can't answer
        such question correctly. Such situation gives human feel of an advantage
        &mdash; not until time when he realizes that human is in the same
        situation.
        </p>
        <p>
        Argument from consciousness is not only about consciousness but also
        about emotions. Turing quotes Jefferson <q>Not until a machine can
        write a sonnet or compose a concerto because of thoughts and emotions
        felt, and not by the chance fall of symbols, could we agree that machine
        equals brain-that is, not only write it but know that it had written it.
        No mechanism could feel (and not merely artificially signal, an easy
        contrivance) pleasure at its successes, grief when its valves fuse, be
        warmed by flattery, be made miserable by its mistakes, be charmed by
        sex, be angry or depressed when it cannot get what it wants.</q>
        Turing responds to this argument that machine can counterfeit such
        feelings and thus it is not important for the test. What is interesting
        here is opening another Pandora's box. Question of emotions and feelings
        quickly became one of the crucial ones. In fact in second half of
        twentieth century it is becoming the primal one in secular society. The
        machine now differs only in its abilities to understand and <q>feel</q>
        emotions. While in the time of Turing crucial trait was
        <q>creativity</q> now it is <q>emotionality</q> as creativity was
        deconstructed and killed by postmoderns. Emotionality now strives to be
        definition of human identity in western world. Where we see this topic
        most embraced is art, so I will elaborate more on this topic in
        <em><a href="#auto-21">Story of Art</a></em>. Now I would stress only one example from
        2015 &mdash; movie <em><a href="#bib-garland_ex_2015">Ex Machina</a></em>
        as it deals with Turing test directly. Humanoid AI is presented to
        interrogator and whole test is reduced to investigating if AI's emotions
        are <q>real</q> or <q>simulated</q>. It is quite illustrating how AI is being treated if
        it is stripped of its securitization aura. Of course there are still
        everlasting topics of responsibility of god-creator, primal sin and
        other christianic overload. But still &mdash; difference between human
        and machine is <q>real</q> emotionality here.
        </p>
        <p>
        It would not be an AI text if it would not mention Lady Lovelace.
        Objection attributed to her is one about creativity. <q>The
        Analytical Engine has no pretensions to <em>originate</em> anything. It
        can do <em>whatever we know how to order it</em> to perform</q>
        (quotation by Turing, italics by Lovelace 1842). This is typical issue
        of that time. Humanity as resulted from Enlightenment project was
        defined by creativity. To be human means to produce new meanings. Turing
        response is critical here. He contradicts term of <q>originality</q>.
        There is nothing new without building on some foundation. If there is no
        independent <q>idea from nothing</q> then learning machine could
        produce same results. Turing is trying to beat the enlightenment beasts
        here. Creativity was definitely a topic for him as also other people
        noted ([<a href="#bib-berrar_turing_2013">Berrar et al., 2013</a>, p. 249]).
        </p>
        <p>
        The other arguments deal more with technicalities and are not so
        interesting for us. Argument from disabilities simply claims, that
        machine will have some flaws. Quick answer is, that every man can't do
        something. It is not about thinking, but about magnitude of thinking (or
        doing). Argument from continuity in nervous system says that human body
        is analogous compared to digital computer. As computer/human is allowed
        only to communicate in written way, this argument is for Turing
        irrelevant. Development of next decades obsoleted it completely. On one
        side analogous computers has risen and on the other side human body is
        no longer treated like analogous machine more like quantum digital
        space. Argument from informality of behaviour is reduction of learning
        problem &mdash; if computer can learn to read, then it can also learn to
        behave according to situation. Last argument is from extrasensory
        perception. Even such thing is Turing evaluating &mdash; telepathy,
        precognition and psychokinesis. He proposes to bracket telepathy out, as
        it infringes the test definition (communication only via written text).
        The rest of text is dedicated to description of learning machines.
        </p>
        <p>
        I've already pointed few topics which have tremendous impact on whole AI
        discourse. Of course that Turing has not invented them, only distilled
        them from contemporary scientific discourse. But terminology and
        approach to AI (word was not used yet in 1950) determined AI as
        anthropomorphic problematic. It is not important that machine can think
        but that <q>thinking</q> is defined as an exclusive human activity.
        Turing is routinely using other anthropomorhic words as
        <q>learning</q>, <q>playing</q> or <q>mental act</q> when speaking
        about machine. I would dare to say that Turing test is so successful
        concept only because it treats AI as human and setting human as a
        measure to it. This definition by relation without investigating what
        runs under the hood of AI seems to be compatible with Habermas'
        <a href="#bib-habermas_habermas_1996">communicative action</a> which
        suggests possibility of its success. Every other definition of AI is
        complex and even incomprehensible, so this one (which is not in fact
        definition at all) is still successful. Here starts the mainstream
        discourse of human-like AI. Ironically, AI scientists sometimes
        understands text as in this example: <q>We believe that Turing
            wanted to encourage us to abandon our anthropocentric view and to adopt
            a broader view on these phenomena.</q> [<a href="#bib-berrar_turing_2013">Berrar et al.,
            2013</a>, p. 249].
        </p>
        <p>
        On one side Turing was thinking about machines as something what will
        merge with people or maybe even something what is identical to people,
        but on the other side he was not able to escape its humanistic origins.
        One of such quotes is here: <q>It is natural that we should wish to
            permit every kind of engineering technique to be used in our machines
            [&hellip;] Finally, we wish to
            exclude from the machines men born in the usual manner.</q> [<a href="#bib-berrar_turing_2013">Berrar
            et al., 2013</a>, p. 254]. This dichotomy between
        machine and man is hunting AI science until transhumanism is born in
        late sixties which finally transcends shackles of humanism.
        </p>
        <p>
        Thin thread connecting text from 1950 with our present could be seen in
        AI discourse. IBM created Deep Blue in 1997 to play chess and beat
        mankind represented by Garry Kasparov. As Berrar quotes him and Martin
        <q>he sometimes saw deep intelligence and creativity in the
            machine's moves [&hellip;] The
            decisive game of the match was Game 2 [&hellip;]
        we saw something that went beyond our wildest expectations [&hellip;] The machine refused to move to a position
        that had a decisive short-term advantage &mdash; showing a very human
        sense of danger.</q> [<a href="#bib-berrar_turing_2013">Berrar et al., 2013</a>, p.
                                 245]. Anthropomorphic approach is still present and
                             legitimized by authority of science, especially by Turing which was put
                             on pedestal decades after his death.
        </p>

        <h4 id="auto-17">1.2.2 Evolution </h4>
        <p>
        Image wouldn't be complete if we don't look to how AI term's meaning is
        changing through the time. We've to found the actors (as there are
        probably some new according to Alexander's note: <q>The exigencies
            of time and space create specific aesthetic demands; at some historical
            juncture, new social roles like director and producer emerge that
            specialize in this task of putting text <q>into the scene</q></q>
        [<a href="#bib-alexander_cultural_2004">Alexander, 2004</a>]) and see in which way they construct this
        term.
        </p>
        <p>
        <q>Intelligence</q> is base term which are we working with. In public
        it is still something taken for granted, but we can note that even the
        word is starting to have contemporary meaning only in last few hundred
        years: <q>Though it is most often assumed to be an ahistorical
            concept, the construction of one's intellectual capacity as being
            <q>normal</q> and another being <q>abnormal</q> only began to appear
            in the English language during the era of industrialization.</q> [<a
                                                                                      href="#bib-nina_lester_discursive_2014">Nina Lester and Gabriel, 2014</a>, p. 778].
                                                                                  Special term which allowed psychology to take <q>expert</q> position on
                                                                                  this [<a href="#bib-goodey_history_2011">Goodey and Dawson Books, 2011</a>].
        </p>
        <p>
        I'll not follow this path further and turn to <q>artificial</q> where
        robot is starting anthropomorhization point. It is interesting, that in
        Czech (from where <q>robot</q> word <a href="#bib-capek_r.u.r._2004">comes</a>) is difference between general robot intended for any work and robot
        which is human-like. This is given by grammatical gender in which the
        world is used (there are only small differences e.g. in plural form
         <q>roboty</q> vs. <q>roboti</q><sup><a id="footnote-15-back" href="#footnote-15">15</a></sup>) but it includes awareness that there are more types of robots. This is
        fading to grey, when it comes to intelligence.
        </p>
        <p>
        One issue is with false implications which connection of
        <q>artificial</q> and <q>intelligence</q> allows. As Gozzi notes,
        construction of public AI legitimacy involved metaphors which were used
        to describe it. Most of them lead to anthropomorphization trap as they
        were used e. g. to compare computer to brain. Simple
        <a href="#bib-gozzi_jr._note_1994">example</a> show
        this false implication. <q>Computer is brain</q> with minor premise
        <q>Thinking is computing</q> leads to conclusion, that
        <q>Sophisticated (AI) programs will give the computer a mind, with
            consciousness, intelligence and other human attributes</q>. As Gozzi
        puts in his research, he sees diminishing usage of strong metaphors as
        AI term gets more and more established. It was no more needed as field
        was set up as legitimate and metaphors can move further, typically to
        Kurzweil's Singularity and transhumanism program. Another reason is that
        AI term can be broadened and re-thinked as something what is not limited
        by its human image. Greer for example thinks about intelligence whose
        subset is human intelligence. So now, AI is freed from human limits and
        is part of <q>something bigger</q> and shouldn't be treated as such.
        </p>
        <p>
        Limits of AI can be seen here. As at first there was no need to compare
        human and AI status, there was simply AI aspiring to human level. From
        this discourse could be selected this (under)definition <q>AI can be
        defined on the basis of the factor of a thinking human being and in
        terms of a rational behavior: (i) systems that think and act like a
        human being; (ii) systems that think and act rationally.</q>
        [<a
        href="#bib-cerka_liability_2015">&#x010C;erka et al., 2015</a>].
        AI is here simply human-equal entity.
        </p>
        <p>
        As transhumanist ideas appeared in the field, problem of comparison
        appeared as well. Transhumanist agenda tried to define AI as something
        better than human, which could be seen in terms of <em>strong AI</em>.
        <q>The <q>strong AI</q> theory asserts that an AI is capable of
            having a mind, as well as mental states; versus the <q>weak AI</q>
            position, which suggests that a machine is only capable of behaving
            intelligently.</q> [<a href="#bib-laufer_artificial_2013">Laufer, 2013</a>, p. 1].
        Ironically this distinction come from the
        <a href="#bib-searle_minds_1980">opponent's side</a> as
        part of argument why it can't work. It provided name for
        new project where AI is condemned to transcend humanity.
        </p>
        <p>
        Twenty years later this project splits to
        <em>AGI</em>
        (Artificial General Intelligence) which is more technical-oriented and
        seriously taken in AI science, while
        <em>Superintelligence</em><sup><a id="footnote-16-back" href="#footnote-16">16</a></sup>
        concept of <em>N</em>.

        Bostrom is some more general and tries to open hands for other
        implementation and criticism. Superintelligence tries to break stigma of
        <q>artificiality</q> and tries get beck to Lamarckian discourse of
        evolution. Bostrom is thus one of biggest proponents of
        <q>naturality</q> of such process. This discursively dissolves
        intelligence perception more generally as it is detached from <a href="#bib-greer_is_2014">natural
            persons</a>. Superintelligence (with its paternalistic tone) also opens way to
        study things like <q><a href="#bib-gladden_social_2014">Charismatic Robot Leader:
             The Superintelligence</a></q>. It somehow removes stigma of Apocalyptic AI.
        </p>
        <p>
        Term <q>intelligence</q> make software more tolerable than others. As
        some applications of software systems which nowadays could be hardly
        called as AI. <a href="#bib-schwartz_artificial_1989">Schwartz</a> shows that using
        the world allows easier deployment of surveillance systems which
        otherwise will cause bigger social resistance. Their intelligence make
        them more human-compatible and less state-power tool. Similar examples
        are taken from places where these <q>expert systems</q> would replace
        some human workers.
        </p>
        <p>
        Completely different chapter is link with science fiction. As
        <a href="#bib-geraci_there_2011">Geraci</a> points even in title
        <em>Transhumanist Evangelism in Science Fiction and Popular Science</em>,
         sci-fi is entangled
        with AI discourse. It on one side serves as generator of ideas and on
        the other it consumes scientific discourse and disseminates it in
        public. From Marxist, more especially Althusser, position we can see it
        as its tool of power. AIs are present in sci-fi almost from the
        beginning and shaped the discourse. Asimov's laws of robotics are
        influential until today and on the other side, concepts of friendly,
        apocalyptic, strong AI or superintelligence is there. Discourse is
        widely shaped by literature and movies and I'll go through it in <em><a href="#auto-21">Story of Art</a></em> as they're not constituent part of scientific
        story, but still quite interconnected with it.
        </p>

        <h2 id="auto-18"><a id="sec:religion"></a>2 Story of Religion </h2>
<div class="quote">
Yes, well, we need a new religion. A principal role of religion
 has been to rationalize death, since up until just now there was
  little else constructive we could do about it.
  <div class="author">
<a href="#bib-kurzweil_singularity_2005">Ray Kurzweil</a>
</div>

</div>
<div class="quote">
Once we saturate the matter and energy in the universe with intelligence, it will <q>wake up,</q>
 be conscious, and sublimely intelligent. That's about as close to God as I can imagine.
 <div class="author"><a href="#bib-kurzweil_singularity_2005">Ray Kurzweil</a></div>
</div>


        <p>
        Turing test as a crucial idea of AI discourse is reopening arena of
        positivist-religion fight. As I've pointed out first and foremost
        objection in that text is from religion. His denial of such argument is
        finished with denoting Copernicus heliocentric issue as similar to AI
        and its soul. This topic is incorporated in scientific narrative almost
        for whole its existence more or less visible and formulated. Existence
        of (non)human soul and consciousness is one of leading motives of
        decades after Turing. On one side it culminates
        <em>inside</em>
        so-called serious science by dispute Searle vs. Kurzweil about argument
        of <a href="#bib-cullen_three_2008">Chinese room</a>, which is at least by second side respected as an ontological dispute.
        On Searle's side I would say, that most of his objections are openly
        religiously deistic and contradictory.<sup><a id="footnote-17-back" href="#footnote-17">17</a></sup>
        The result is that two sides completely discoursively <a href="#bib-kurzweil_singularity_2005">miss each other</a>
        and are not able of any meaningful communication in Habermas' sense.
        </p>
        <p>
        To look into story of religion we have to go broader. As discourse
        contains a lot of references to other fields, we need to deal with
        concepts like <q><a href="#bib-geraci_apocalyptic_2008">Apocalyptic AI</a></q>
        or <q><a href="#bib-kurzweil_singularity_2005">Singularity</a></q> trope.
        What connects all these issues with AI are transhumanist and in its
        extension posthumanist movements.
        </p>
        <p>
        In first instance we will look to these movements via prism of Implicit
        Religion (IR). According to <a href="#bib-bailey_implicit_1998">Bailey</a>
        implicit religion can be described be three
        definitions. First is about <em>Commitments</em> which can be also
        unconscious. It is connected to free will and can emerge in the moment
        of <em>crisis</em>, Second definition is <em>Integrating foci</em>.
        There are moments in life which ties together all components of IR.
        Thus, this concept is permeating to all levels of identity and society
        in sense both of <em>gesellschaft</em> and <em>gemeinschaft</em>. Third
        is <em>Intensive concerns with extensive effects</em>, All three ideas
        bound together give us some framework how to image IR. It can be almost
        anything (Bailey's examples are IR of pub or suburbian life), so it
        shouldn't be merged together with terms like civil, invisible, folk or
        popular religion. These can be interpreted as special cases of IR, but
        it provides much broader framework. We can interpret AI movement from
        this unconscious IR interpretation of <q>secular</q> scientists to
        institutions of explicit religion (Turing Church, Mormon Transhumanist
        Association). Whole transhumanist and posthumanist movement can be
        interpreted via third definition. Living habits like <a
        href="#bib-geraci_novel_2014">reading sci-fi</a> can be treated in <em>integrating foci</em>,
        paradigm, etc.
        </p>
        <p>
        Posthumanism itself is fascinating example of enlightenment project
        impact. Definitive victory of science over religion and shackles of man.
        This creed is allowed by philosophical development which can be traced
        back to the enlightenment period and which culminates with conference
        series of <em>Josiah Macy Foundation</em> (1946&ndash;1953).
        Individualization of man is crowned by removing his special status in
        the universe and pursued by <q>&hellip;a new theoretical model for
            biological, mechanical, and communicational processes that removed the
            human and Homo sapiens from any particularly privileged position in
            relation to matters, meaning, information, and cognition</q> [<a
                                                                                  href="#bib-tirosh-samuelson_transhumanism_2012">Tirosh-Samuelson, 2012</a>, p. 711] It is in
                                                                              consistency with what Foucault and Derrida describes as decline from
                                                                              <q>man-centered universe</q> in almost the same way as Latour notes
                                                                              <q>The expression <q>anthropomorphic</q> considerably
                                                                                  underestimates our humanity.</q> [<a href="#bib-latour_we_1991">Latour and Porter,
                                                                                  1991</a>, p. 137].
        </p>
        <p>
        This pursue quickly escalates to removal of <q>classical</q> concept of
        man from the prevailing discourse of evolution. Evolution in
        transhumanism should continue in so-called protestant ethics of
        self-improvement which now contains also removing of body sanctity. Such
        improvements now consists also from self-modification. In its simplest
        case it is just taking some pills. In its harder-way by cyborgization
        and modification of one's DNA. Such man will technologically and
        genetically supersede the <q>conventional</q> man and will become
        Nietzsche's
        <em>&Uuml;bermensch</em>
        finally.<sup><a id="#footnote-18-back" href="#footnote-18">18</a></sup>
        </p>
        <p>
        From here it is quite simple to remove concept of man at all and take
        one more step to posthumanism and condemn man forever. This inherently
        bad creation of evolution should be forgotten and substituted by
        evolutionary higher creature &mdash; <q>post-human existence</q> where
        human is obsoleted by postbiological and post-Darwinian stage of
        <a href="#bib-tirosh-samuelson_transhumanism_2012">human development</a>.
        </p>
        <blockquote>
                <p>
                Substrate is morally irrelevant, assuming it doesn't affect
                functionality or consciousness. It doesn't matter, from a moral
                point of view, whether somebody runs on silicon or biological
                neurons (just as it doesn't matter whether you have dark or pale
                skin). On the same grounds, that we reject racism and speciesism, we
                should also reject carbon-chauvinism, or bioism. (N. Bostrom
                in [<a href="#bib-kurzweil_singularity_2005">Kurzweil, 2005</a>])
                </p>
        </blockquote>
        <p>
        Kurzweil's bible of posthumanism and technological singularity ideology
        <em><a href="#bib-kurzweil_singularity_2005">Singularity is Near: When Humans Transcends Biology</a></em> is full of similar religious aspects as whole ideology. We
        will see that there is almost nothing new and we know all these concepts
        from history of Christianity. For now we just say with
        <a href="#bib-geraci_apocalyptic_2008">Geraci</a>,
        that we can encounter new creature creation, unavoidable
        apocalypse, possible transcendence for chosen which allows surviving it,
        New Jerusalem of human patterns (where man is no more a creature but
        time-based intelligence pattern) uploaded in network encircling whole
        universe.
        </p>
        <p>
            Tirosh-Samuelson tracks importance of cybernetics in transhumanism
            ideological base <q>Whereas Heidegger saw it as the
                <q>apotheosis of Cartesian humanism,</q> Jean Pierre Dupuy has argued
                that cybernetics represented a crucial moment in its demystification and
                indeed the deconstruction of humanism. For Dupuy, <q>cybernetics
                    consisted of a decisive step in the rise of antihumanism</q> (Dupuy 2011,
                228), by which he means (following Hannah Arendt) the <q>rebellion
                    against human existence.</q> </q> [<a href="#bib-tirosh-samuelson_transhumanism_2012">Tirosh-Samuelson,
                2012</a>, p. 712].
        </p>
        <p>
            <q>The Singularity</q> is the ultimate point of evolution of man. There
            is nothing behind it what can be carved by biological man, the future
            behind this point of no return is unknowable. It is quite connected to
            Apocalyptic AI and as Geraci puts it: <q>The singularity is the
                point on the graph of progress where explosive growth occurs in a blink
                of an eye; it is the end of history and the beginning of the new world
                and it is closer than you think.</q>
            [<a href="#bib-geraci_apocalyptic_2008">Geraci, 2008</a>, p. 149].
            There is generally no link of <q>old
                man</q> with new world (and we will see this more closely in
            <em><a href="#auto-20">Story of Securitization</a></em>),
            typical variant is <q>Eventually, the machines will tire of caring
                for humanity and decide to spread throughout the universe in the
                interest of discovering all the secrets of the cosmos (though perhaps
                some will remain behind).</q>
            [<a href="#bib-geraci_apocalyptic_2008">Geraci, 2008</a>, Moravec in p. 151]
        </p>
        <p>
        There are two threads <q>whereas the technological posthumanists see
            themselves as a continuation and even intensification of the
            Enlightenment Project and glorify human reason and its ability to
            improve the world, philosophical/cultural posthumanists critique the
            Enlightenment Project because of its flawed metaphysics and harmful
            social consequences.</q> [<a href="#bib-tirosh-samuelson_transhumanism_2012">Tirosh-Samuelson, 2012</a>,
        p. 715].
        </p>
        <p>
        When we go to question when enlightenment projects ends and where
        religious path starts we will see almost clear division on
        present/future border. <q>The former is straightforwardly secular,
            indeed a continuation of nineteenth-century humanistic naturalism and
            utilitarianism, while the latter is saturated with religious themes: its
            mentality is apocalyptic and its orientation is eschatological.</q>
            [<a href="#bib-tirosh-samuelson_transhumanism_2012">Tirosh-Samuelson, 2012</a>, p. 716].
        <sup><a id="footnote-19-back" href="#footnote-19">19</a></sup>
        I can take Bibel and his salvation ideology as typical example, where
        people has weaknesses like us selfishness, limited rationality, etc. To
        fix it we can <q>either change human nature or compensate the
            weaknesses in an organizational and technical way based on Zusean
            thinking. [&hellip;] This <em>Zusean alternative</em>
            means that we attempt to build an artificially intelligent agent which
            on the one hand matches human intelligence and on the other does not
            suffer from human weaknesses and failures.</q> [<a href="#bib-bibel_artificial_2014">Bibel, 2014</a>, p. 89].
        <sup><a id="footnote-20-back" href="#footnote-20">20</a></sup>
        Finally he sees salvation and long-term guidance in AI <q>What
            mankind would need is a super-human intelligence which on the basis of
            all available knowledge always would follow the rules of consistent,
            logical and rational thinking taking a global and far-sighted
            perspective.</q> (Ibid, p. 100) going to such extreme that he proposes to design AI which will
        propose Kantian <q>world's fundamental constitution.</q> (Ibid). This
    unworthiness of mankind can be described via more engineering means as
    mankind should be replaced because its computational capacity is low and
    <a href="#bib-tegmark_friendly_2014">limited</a>. Motivation why there should be any capacity is driven by belief in
    enthropy and opinion that high enthropy is <q>boring</q>.
        </p>
        <p>
        It is sometimes difficult to set some topic to religious narrative or to
        science/materiality as it simultaneously hits both. Such case is
        relationship between body and religion. Concept of soul is inherently
        connected to body as there is no soul without body except heaven. As
        Christians strive for resurrection, it makes no sense for transhumanists
        who don't need body anymore. They are able to transcend even the body.
        Once again here steps into the game Teilhard de Chardin reintepreted by
        Ray Kurzweil as someone who can reconciliate Christianity with
        trans/posthumanism. AI raises once more question about which values can
        be learned by AI and which has to be <q><a href="#bib-dodig_crnkovic_robots:_2012">loaded</a></q>. Even here we meet ideas that religious belief (which means of course
        Christianity as almost any other religions are not interested in AI)
        should be preloaded [<a href="#bib-mercer_bodies_2015">Mercer, 2015</a>,
        <a href="#bib-fernandez_castro_shaping_2014">Fern&aacute;ndez Castro, 2014</a>].
        Even AI's existence can be taken as holy quest. In case of Mormonism
        it is very easily integrated and it is even becoming one of the ultimate
        goals of church<sup><a id="footnote-21-back" href="#footnote-21">21</a></sup>.
        In any case, classic religion is becoming interested in AI and devotes
        some of its resources to deal with the topic. It is not by chance, that
        same people are pointing to transhumanist belief that AI is inherently
        good with note <q>If you model it after the human, you have to
        expect also human capacity for sin</q> (paraphrased <a href="#bib-mercer_bodies_2015">Mercer</a>).
        </p>
        <p>
        What will reveal us more about Christian roots of AI religion is when we
        look to others how they deal with possible conscious machine. First,
        less interesting, is Buddhism represented by Dalai Lama's response to
        such question as he <q>can't totally rule out the possibility that,
            if all the external conditions and karmic action are there, a stream of
            consciousness might actually enter into a computer.</q> (quoted in
        [<a href="#bib-tamatea_online_2010">Tamatea, 2010</a>, p. 987]). Tamatea in his
        empirical research comes to conclusion, that real Buddhist response is
        in fact quite similar to Christian even counter to canon that says that
        God is equally present in everything. Notable difference is only in
        concept of <a href="#bib-geraci_apocalyptic_2008">Apocalyptic AI</a>. This is not
        present in Buddhism as it has no eschatological version. It implies,
        that there is no fear from science as a tool to end of the world. What
        is also reflected here is that AI would be religious &mdash; it makes no
        sense to not be.
        </p>
        <p>
        Japan with its philosophical origins in shintoism is even further than
        Buddhism and it seems that it have nothing to say to euroamerican
        discourse. Soul is part of everything thus discussion if something (AI)
        has soul is nonsensical. Border between living and artificial being is
        indistinct, easily crossed. Whole western obsession by question if AI is
        creature (ergo has intentionality, soul or consciousness) seems to be
        incomprehensible to this culture. One of most popular contemporary
        artists is <em>Hatsune Miku</em> &mdash; synthesizer generated voice
        with 3D projected body. For Japanese it is a creature for which they
        will use same word as for a <a href="#bib-robertson_robo_2007">person </a> and it
        doesn't mean that they would succumb less to her charisma on concert
        than to western superstars.
        </p>
        <p>
        Now if we've some starting point for Christianity, lets go back to it.
        Jewish account is more problematized by fact, that it is ethnicized
        religion. As such there is more than <q>just</q> teleological
        explanation. Science in itself is not in conflict with current state of
        religion and as <a href="#bib-samuelson_jewish_2012">Samuelson</a> suggests,
        there is also in play genetic interest due to large
        prepondrance to inherited genetic issues. Such interest also modifies
        official stance of religious authorities. So, there is not anything what
        would stop Jewish religion from supporting science and transhumanism.
        The problem of AI consciousness is put to second line and is partially
        solved by positive Kabbalah stance. We've evidence even from seventeenth
        century of discussion whether golem can be included in <em>minyan</em>
        and similar discussions continues to twentieth solving whether
        artificial person can be granted the legal status of
        <a href="#bib-sherwin_golems_2007">natural person</a>.
        </p>
        <p>
        For Sunna, Shia and Sufism is quite hard to find almost anything. There
        is anecdotic sunnic <a href="#bib-owaied_new_2012">evidence</a>, where
        Owaied proposes to study AI through Quran which says not much, but at
        least signals perceived compatibility of Quran with AI creation.
        <a href="#bib-mahootian_ideals_2012">Mahootian</a> says, that Sufism is ready for
        transhumanism by definition. There is a simultaneity of disclosure and
        recognition in Suhrawardi's and ibn al-Arabi's ideology and this makes a
        basic epistemological point. From here is relatively open road to create
        AI in consistency with God. In discussion is if <em>alam al-mithal</em>
        could be somehow related to world of digital self and AI. <em>Alam
            al-mithal's</em> properties as place <q>where soul builds the
            pattern of its resurrection body</q> [<a href="#bib-mahootian_ideals_2012">Mahootian, 2012</a>,
        p. 148] reminds disembodied AI and possibility of its
        instantiation. Sufism via Ismailism also perpetrated Shia and brought
        there such notions.
        </p>
        <p>
        From here we can jump to Orthodox church as it is influenced by both
        previous. <a href="#bib-clay_transhumanism_2012">Clay</a> studies
        seventh century's
        Maximos the Confessor. His (re)definition of orthodox teachings sets
        free will (thel&emacr;ma) as part of
        human nature (phusis) with its own activity (energia). Human being is
        here a God's partner and in the same time concept of created and
        uncreated energies allows building of AI without problems. Compared to
        Buddhism and also Sufism (apocalyptic Islam not included) Christianity
        opens topic of eschatology. Russian orthodox contribution to
        AI/transhumanism is mostly via Nikolai Fyodorovich Fyodorov who was
        focused on this topic, immortality and resurrection of all dead as final
        project of Christianity. His ideas, while so wild, influenced not only
        later transhumanism but also project's like Tsiolkovskii's rocket
        science with goal to have space for the resurrected.
        </p>
        <p>
        Western Christianity is most concerned with AI. I've already shown
        parallels which are taken to AI/transhumanism from Christianity. From
        the other side there is a lot of concerns. As <a href="#bib-tamatea_online_2010">Tamatea</a> notes, christian reactions are often linked with fear of
        science related to eschatological explanations. Polarity between thing
        and being was also stressed on other place, but it is one of the leading
        topics in christian literature. Division between human and animal is
        <a href="#bib-koosed_bible_2014">concerned</a>. This is not running only on level
        of <a href="#bib-stannard_god_2000">thing-being</a>, but also (and maybe more
        important, as human-thing is solved by defining it) human-animal level
        [<a href="#bib-koosed_bible_2014">Koosed, 2014</a>, <a href="#bib-garner_theology_2011">Garner, 2011</a>]. <em>Torn between
            body and soul</em> is a long-term problem here and it is emphasized by
        cyborgizing bodies and theories of religion embodiment. In such moment
        christianity have to deal with moment when man becomes thing [<a href="#bib-stannard_god_2000">Stannard,
            2000</a>, <a href="#bib-cole-turner_transhumanism_2011">Cole-Turner, 2011</a>].
        </p>
        <p style="margin-top: 1em">
        Why is so much religion in AI? One answer is the paraphrased Latour
        &mdash; <q>We've never been secular</q> theory. Technoanimism (as we've
        already hit it in materiality section) is inherently present whole time
        and in postsecular society just more visible. As a primitive belief it
        could be present in IT as <a href="#bib-aupers_revenge_2002">Aupers</a> suggests.
        He meets Habermas here to say <q>Science has no secular project</q>.
        Even if everybody else moved to post-secular period, it is not the case
        of absolutist science.
        </p>
        <p>
        Less aggressive position is from Habermas himself. He opens need for
        some transcendental belief as a result of modernity.
        </p>
        <blockquote>
                <p>
                In moments like these [facing Holocaust], the unbelieving sons and
                daughters of modernity seem to believe that they owe more to one
                another, and need more for themselves, than what is accessible to
                them, in translation, of religious tradition  &mdash;
                as if the semantic potential of the latter was still not
                exhausted. [<a href="#bib-habermas_future_2003">Habermas, 2003</a>, p. 111]
                </p>
        </blockquote>
        <p>
        I can finally mix it together with Christian roots and say with
        Horkheimer <q>Knowing there is No God, it nevertheless believes in
            him</q> (in [<a href="#bib-habermas_future_2003">Habermas, 2003</a>, p. 113]).
        Eschatology as coming from classical Christian teaching and from the
        other side as fear from liquid modernity is being melted together in not
        completely new but rebuilt religion of AI with all its eschatological
        and transcendental promises. End of the world is on one side of
        discourse feared and on the other embraced [<a href="#bib-geraci_robots_2007">Geraci, 2007</a>,
        <a href="#bib-mcintosh_transhuman_2010">McIntosh, 2010</a>, <a href="#bib-kurzweil_promise_2001">Kurzweil, 2001</a>, <a href="#bib-geraci_apocalyptic_2008">Geraci,
            2008</a>, <a href="#bib-mehlman_transhumanist_2012">Mehlman and Project Muse, 2012</a>].
        </p>

        <h2 id="auto-19"><a id="sec:alchemy"></a>3 Story of Alchemy </h2>
<div class="quote">

The computer programmer is a creator of universes for which he alone is
 the lawgiver. No playwright, no stage director, no emperor, however powerful,
  has ever exercised such absolute authority to arrange a stage or a field
   of battle and to command such unswervingly dutiful actors or troops.
   <div class="author"><a href="#bib-weizenbaum_computer_1976">Joseph Weizenbaum</a></div>
</div>
<div class="quote">

<q>No, it's that empathy,</q> Irmgard said vigorously. Fists clenched,
 she roved into the kitchen, up to Isidore. <q>Isn't it a way of proving
     that humans can do something we can't do? Because without the Mercer
      experience we just have your word that you feel this empathy business, this shared, group thing.</q>
      <div class="author"><a href="#bib-dick_androids_1996">Philip Kindred Dick</a></div>
</div>

        <p>
        Is related to story of religion. But it is more connected to hermetism
        and more limited to the moment of creation. As I've already noted in the
        introduction, roots of this movement can be traced thousand years back.
        Three main aspects are present. First is almost total
        anthropomorphization. Real goal of this branch is <em>The Creature</em>.
        It is not purely utilitarian approach from story of science. It is
        mystical attempt to recreate human. Model scenarios are striking with
        their detachment from <q>reality</q> as they are describing human
        behaviour not anything what could be expected from current state of AI
        science. <q>&hellip;previous robot team leader has been killed, and
            several other robots have been either tortured or physically abused. In
            one case, one of the sentient robots is even used as a slave for
            another. Some of the robots are now imprisoned and are ritually abused
            according to their physical attributes or company of origin.</q> as
        Ashrafian describes potential legal situation [<a href="#bib-ashrafian_aionai:_2015">Ashrafian,
            2015</a>]. Not to mention, that Neuman, Wiener or Minsky recognizes
        alchemist heritage by linkage with Rabbi L&ouml;w's <a href="#bib-aupers_where_2010">golem</a>.
        </p>
        <p>
        Second is what <a href="#bib-davis_techgnosis:_1998">Davis</a> calls
        <em>Techgnosis</em> or <em>Technomysticim</em>. Assemblage of wild
        belief in technology, combined with sense of awe from mysteries hidden
        and being recreated there &mdash; it is everything what modern alchemy
        is. Starting with Newton and ending in today's cults of
        ghost-in-the-machine. This part is mostly interconnected with chapter
        about religion (and in fact would be best understood in terms of
        implicit religion), but I'll use it here as a glue.
        </p>
        <p>
        Third aspect, directly implied by first, is ethics of the machine. We've
        already touched this problem in section about materiality. But there is
        still some maneuvering space even with limitation imposed by
        materiality. So let's investigate how scientists are thinking about this
        issue. Basic questions asked here are following. Which moral code should
        such creature have? What is the way how this code should be given or
        taught? Question of ethics is quickly moving from ontological level to
        epistemology. Another basic contradiction is emerging here: If ideal AI
        is condemned to human epistemology (inseparably connected with
        predesigned ethics), but in the same time has to outrun him on every
        thinkable level, which ideally means better (or at least different)
        epistemological capacity. From the point of ethics it seems inevitable
        to give AI free will. Kantian ethical system is one where this
        contradiction can be seen most easily.
        </p>
        <blockquote>
                <p>
                Once this question [whether Kantian ethics permits the development
                of autonomous moral agents] is asked, it becomes clear that creating
                Kantian artificial moral agents is anti-Kantian. On one hand,
                Kantian moral machines would not be Kantian moral agents, strictly
                speaking. On the other hand, even if such machines were Kantian
                moral agents, their creation would nevertheless violate Kantian
                moral law. Because of this, the creation of Kantian AMAs is
                inconsistent with the prescriptions of Kantian morality. Since we
                (rightly) demand consistency in ethics, the failure of such machines
                to meet the standards of morality that they are designed to heed is
                unacceptable. We risk creating machines that may come to understand
                their very existence as being unethical. Moreover, we would be
                asking such machines to act in accordance with a moral code that we
                violated through the act of creating them. [<a href="#bib-tonkens_challenge_2009">Tonkens,
                    2009</a>, p. 422]
                </p>
        </blockquote>
        <p>
        From sociological perspective is interesting that even discussion about
        origins of morality doesn't reflect on its roots and is not even
        disturbed by that its own positions are not defensible in discussion or
        are even internally dogmatic. <q>The only way to develop authentic
            Kantian moral agents would be to create AMAs that are free to the extent
            that they can sometimes choose to act immorally. This is most likely not
            a consequence that machine ethicists would be willing to accept,
            <em>and rightly so</em>.</q> [<a href="#bib-tonkens_challenge_2009">Tonkens, 2009</a>
        , p. 431]<a id="footnr-22"></a><sup><a id="footnote-22-back" href="#footnote-22">22</a></sup>
        Objection from context could be raised. I believe it is not in the
        place as there is a lot of other texts which builds on these
        non-reflected positions like what is <q>right</q>. In philosophical
        text trying to find <q>best</q> moral code is disturbing that it has
        <em>a priori</em>
        positions which are not taken to the mind. Of course, that these
        contradictory problem not hit only Kantian ethic, but almost in same way
        also Mill's or Bentham's versions of utilitarianism. There are some
        proposals how to get from the anthropomorphization trap in Latourian way
        of ethical code where things and humans are treated same or at least
        similarly [<a href="#bib-floridi_morality_2004">Floridi and Sanders, 2004</a>,
        <a href="#bib-coeckelbergh_virtual_2009">Coeckelbergh, 2009</a>].
        </p>
        <p>
        Whole alchemy line is one which brings anthropomorphization in most
        visible way. In many cases without reasons, in others there is
        underlying securitization story based on thesis: AI will not harm
        mankind only in case that it will be human-like.
        </p>
        <p>
        Here comes partly <q>mystical</q>, partly already deconstructed
        inclination to humanization of machines. We see many attempts from old
        cultures to contemporary ones when people are trying to make machines
        look sentient. from moving statues in old Greece or Egypt to famous von
        Kemplen's <q>chess machine</q> with hidden player. Pre-AI software is
        working in less obvious way but still it was deception and no real
        sentience (e. g. <a href="#bib-weizenbaum_eliza--computer_1966">ELIZA</a>). <a href="#bib-sharkey_artificial_2006">Sharkey</a> goes
        through this history and shows us how <em>cultural myth of robotics</em>
        was established. Via Alexander's strong program of cultural history he
        shows, how robots where established as cultural property shortly after
        <a href="#bib-capek_r.u.r._2004">R. U. R.</a> in 1920 was released. Machines which were <q>mechanical
            boxes</q> until that time has started to acquire human-like visage. In 1927
            Westinghouse produced simple machine &mdash; in fact small phone
            central. The Televox was from marketing reasons turned via so-called
            &#x010C;apek's effect to <q>mechanical man</q>. Two boxes which were
            enhanced by hands and legs via newspaper's comics. It started new mode
            wave <q>Anything that had a sensor was called a robot.</q> This
            is short example how quickly are people able to attribute human traits
            to machine. There are psychological experiments which shows us that
            people create attachments to computer and even more to androids. There
            is a lot of therapeutic robots which are exploiting exactly this
            <q>feature</q>.
        </p>
        <p>
        Interesting effect of business applications can be viewed from gender
        studies prism. There is running discussion about <q>gendering</q> AIs
        and robots. One stance is that they shouldn't be gendered at all (voice
        of AI should be genderless) to not reify stereotypes. On the other side
        is business push which wants to use psychological effect of
        anthropomorphization and in its extent &mdash; gendering. People better
        respond to genderized machines, they behave differently if wo/man like
        robot is present. Of course to create robot with correct sex is easiest
        done by emphasizing gender stereotypes. Some effects of this are clearly
        visible, while other could have some impact in the future [<a href="#bib-adam_artificial_1998">Adam,
            1998</a>, <a href="#bib-marchetti-bowick_is_2009">Marchetti-Bowick, 2009</a>, <a href="#bib-hrisca_artificial_2012">Hri&#x015F;c&#x0103;,
            2012</a>, <a href="#bib-larson_artificial_2010">Larson, 2010</a>, <a href="#bib-shaw-garlock_gendered_2014">Shaw-Garlock, 2014</a>].
        </p>
        <p>
        Where this part has the most harming effects is definitely military
        today
        <sup><a id="footnote-23-back" href="#footnote-23">23</a></sup>
        &mdash; we see that this issue matters: <q>US army colonel who was
            in charge of a test of one of Tilden's legged robots in a minefield. The
            robot, modelled on a stick insect, successfully detonated a number of
            mines and lost a leg each time. It was dragging along very successfully
            when the distressed Colonel in charge stopped the demonstration because
            he thought that the test was inhumane.</q> [<a href="#bib-sharkey_artificial_2006">Sharkey and Sharkey, 2006</a>
        , p.

        13]. We can imagine some impacts of this. When we are nearing to AI,
        human response is slowly changing from idea that robot is <q>alive</q>
        to idea that AI has <q>mind</q> and is <q>conscious</q>. Sharkey
        concludes that it is almost inevitable that AI designers also have to
        fall into the trap and they'll treat their products as conscious even if
        it is just a simple box with two wires.
        </p>
        <p>
        There are few hypotheses, why even in these secular and post-secular
        times are scientists so susceptible to hermeticism and generally
        mysticism of technology. Let's start with <q>Long before Weber wrote
            about disenchantment, the world was already disenchanted by
            monotheism</q> [<a href="#bib-coeckelbergh_pervasion_2013">Coeckelbergh, 2013</a>] Secularization
        thesis is extended by Coeckelbergh to this extreme. What killed
        enchantment is one God, not removal of God. Christian God defined (of
        course in its ideal variant) the material world as world without spirit.
        This is probably the first time in history when things are really dead.
        When this line is breached, monster appears &mdash; Frankenstein. There
        is some possibility of <q>aura</q> bestowed by author to its creation,
        but this aura is being lost in modern age with mass production. This
        idea is starting with Marx and even more explicitly with Benjamin.
        Information technology emphasizes this problem as artefact is also lost.
        Information is not artefact and it is not human also but it is pervading
        everything. Its status is threat to ontological concept of human
        identity. Latourian way of returning things into play could be seen as
        re-enchantment of the world. His removal of dichotomy between <em>works
            of purification</em> and <em>works of translation</em> is trying to
        retie the world <q>back together</q>. It is also expressing some
        sentiments but in new post-modern way. In less scientific interpretation
        it simply means putting spirit back to things which is exactly what AI
        discourse does. It is no more transcendent spirituality but
        <em>immanent</em> one as Coeckelbergh correctly notes. This immanent
        spirituality is something what I would place in this alchemy line
        without hesitation. There is also short way to fear of such creations as
        they're more created <em>in imago humani</em> [<a href="#bib-herzfeld_creating_2002">Herzfeld,
            2002</a>, <a href="#bib-herzfeld_empathetic_2015">Herzfeld, 2015</a>].
        </p>
        <p>
        Part of alchemy is creation of superhuman. We can trace thin thread from
        Lamarckian evolution to eugenics (which is in its modern form inherently
        connected with <a href="#bib-mul_cyberspace_2010">trans and posthumanism</a>).
        Teilhard de Chardin is leading figure of philosophy of AI and especially
        appreciated by singularity theorists. His vision of <q>Noosphere</q>
        and <q>Omega Point</q> were almost without changes, just with removal
        of poetic balast and transformation to science-like narrative.
        All-encompassing purpose of mankind was taken from this Jesuit and
        rebranded to something without inner consistency previously provided by
        Christianity. Language of Kurzweil and Bostrom is built on destiny of
        intelligence. From Noosphere is <q>conscious universe</q> and from
        Omega Point &mdash; Singularity. Intelligence is a pattern of life which
        has to expand as Lamarck's heritage. Tendency is taken for reason. What
        <a href="#bib-fuller_knowledge_2009">Fuller</a> shows, is mix of non-reflected
        Christian origins with <q>blind</q> science shifts focus in last
        decades from <em>simulating</em> to <em>instantiating</em> of life and
        he explains it: <q>The language of <q>instantiation</q> derives
            from theological discourses of the Christian deity's triune nature,
            i. e. the idea that God is subject to three equally
            divine manifestations: Father, Son and Holy Spirit. These theological
            roots go beyond historical curiosity to a general principle of Biblical
            interpretation that provides a precedent for reducing, if not erasing,
            the differences between processes, entities and interventions of
            <q>artificial</q> and <q>natural</q> origin.</q> [<a href="#bib-fuller_knowledge_2009">Fuller,
            2009</a>, p. 14] Science finally playing God &mdash;
        this paradigm switch has direct impact to society also. Fuller <a href="#bib-fuller_knowledge_2009">argues</a> with U.S. circuit court case in which this changed concept of
        instantiation was used as argument against creationist defendants. Judge
        simply took for granted that simulation of primitive life in computer is
        no more simulation but life itself. This example can from some point be
        seen as a fair fight of two religious paradigms. Such interpretation
        would be fair via Habermas' notion of communicative action, but it is
        not perceived as such in science with its ultimate right on objective
        truth. Fuller is pointing to probable self-fulfilling prophecy character
        of such shifts and its reification by legitimacy of court authority.
        There is a potential that concept of life will be redefined in future
        based on this paradigm shift. There are already some attempts to this
        &mdash; what is unpredictable is <a href="#bib-aupers_where_2010">alive</a>. In
        Wittgensteinian interpretation it means, that we've nothing more to talk
        about. Problem noted in this text will simply disappear in language
        which will not involve term of life (when everything is alive aka in
        Kurzweil's and de Chardin's conscious universe).
        </p>

        <h2 id="auto-20"><a id="sec:securitization"></a>4 Story of Securitization</h2>
        <div class="quote">
Suppose someone were to say, <q>Imagine this butterfly exactly as it is, but ugly instead of beautiful.</q>
<div class="author"><a href="#bib-wittgenstein_zettel_1967">Ludwig Wittgenstein</a></div>
</div>

        <p>
        Securitization is term borrowed from International Relations created by
        so-called <a href="#bib-buzan_security:_1998">Copenhagen school</a>. It means
        politicization of some topic via its relation to security issues.
        Important is that it is talking about security as about speech acts and
        in our case it is view which allows us to see how (potential, perceived
        or imagined) AI security issues influence real-world and science
        progress.
        </p>
        <p>
        This story connects all previous. Concerns from AI and science in
        general is leitmotif here. AI as a grave danger is framing of almost any
        public discussion of the topic. It does not depend if it is a religious
        counterargument or simple positivist calculation how much time is needed
        for uncontrolled self-replication nanobot to
        <a href="#bib-kurzweil_singularity_2005">destroy whole planet</a>.
        </p>
        <p>
        Fear of being destroyed by own progeny once again follows old myths
        represented e.g. Zeus' revolt against Titans. In relation to AI will be more
        interesting modern incarnation in &#x010C;apek's novel
        <em><a href="#bib-capek_r.u.r._2004">R.U.R.</a></em> or in the later world-known novel
        <em><a href="#bib-dick_androids_1996">Do Androids Dream of Electric Sheep?</a></em><a id="footnr-24"></a><sup><a id="footnote-24-back" href="#footnote-24">24</a></sup>.
        These myths are forged to concrete fears which are based on specie or
        at least group rivalry. If AI will be created what is the probability
        that it will be human-compatible? What will stop AI from enslaving
        mankind? Will AI have any cognitive capacity to even perceive humans?
        Whole this category of questions is leading us to two sides of quarrel
        &mdash; first is abolitionist movement which wants to stop everything
        before self-improving AI will be unstoppable. On the other side is an
        effort to make AI compatible from design and in second row to build
        ethical-legal frame for coexistence.
        </p>
        <p>
        Especially question of legal framing is quite interesting. Technicist
        branch is still rooted in Asimov's three laws of robotics [<a href="#bib-asimov_i_1977">Asimov,
        1977</a>, <a href="#bib-khalil_artificial_1993">Khalil, 1993</a>] and is set in defensive mode.
        Compared to it humanist line is based on human/AI equality thesis and in
        its weaker mode on animal rights argumentation. This line could be also
        split to part which opposes Anglo-Saxon legal order together with
        Christian tradition where man is qualitatively different and such order
        is formed to his defense. Main objection is that if animal rights were
        already admitted as substantially independent (so not as defence of
        their owner's rights) the taboo is already broken and there is no reason
        why to not extend these rights to AIs. Second line is rooted in
        discourse promoted by <a href="#bib-singer_animal_1975">P. Singer</a>. In
        connection with human rights the new interesting mix is born. Some
        rights are confirmed, while not every <a href="#bib-ashrafian_aionai:_2015">one of them</a>.
         Field is quite large and has origins in anthropocentrism,
        biocentrism or ecocentrism with all their historical <a href="#bib-torrance_artificial_2013">baggage</a>.
        Whole discourse almost logically expands to bigger issues
        like <q>when man is still man</q> and <q>when AI is ready for its
                rights</q>. This is the point where sociologically relevant authors enters
            the field: Barthes, Baudrillard or Husserl with human identity as a
            social construct, etc. [<a href="#bib-hrisca_artificial_2012">Hri&#x015F;c&#x0103;, 2012</a>]
        </p>
        <p>
        This partly scientific and partly public discourse is further propagated
        to legal norm proposals. Their genesis and construction are also
        interesting. One of the origins is already mentioned Asimov (note, that
        this is the <q>art</q> input) and second quite influential is
        historical experience with legal norms for
        <a href="#bib-habermas_future_2003">genetic manipulations</a> and virus treatment. Proposals which are
        dedicated to transformation to laws are brought to live [<a href="#bib-veruggio_euron_2007">Veruggio,
            2007</a>, <a href="#bib-ashrafian_artificial_2014">Ashrafian, 2014</a>, <a href="#bib-field_south_2012">Field, 2012</a>]. They
        are still not real laws, but media works with them as witch such. It is
        more connected to discursive construction than to securitization.
        Practical norm which at least someone adheres to are <em><a href="#bib-epsrc_principles_2010">Principles of
            Robotics</a></em> or EU <a href="#bib-robolaw_guidelines_2014">proposals</a>.
        </p>
        <p>
        Beside these proposals which are more utopia than reality what we hit is
        problematic of software (and robot) responsibility. First trials are
        being run, where judges tries to answer question about who &mdash; if
        its operator, manufacturer or drone itself &mdash; is  <a href="#bib-hallevy_when_2013">responsible</a> for
        drone's actions. Part of the field is
        completely serious discussion about how AI should be persecuted if found
        guilty. Proposals for limiting some of their rights, jury's right to
        turn it off (as a euphemism to capital punishment) puts a mirror to how
        these rights, ethical and democratic foundations are perceived in
        concrete communities. Habermas theory of <a href="#bib-habermas_habermas_1996">communicative ethics</a> can enlighten some aspects. For example even if
        AIs are in this discourse treated as completely human-equal they are not
        permitted to anyhow participate on legal system. Only some extremist
        positions hold on that AI will be part of a <a href="#bib-kurzweil_singularity_2005">democratic process</a>. Question of political rights of AIs is for most of the actors
        completely unacceptable and this non-acceptance is in direct
        contradiction with their egalitarian position.
        </p>
        <p>
        AI as a danger (and here I omit other variants as an ecological threat,
        etc.) is main argumentation line of AI antagonists. Ethical or religious
        issues takes place behind this flagship.
        </p>
        <blockquote>
                <p>
                Nor is there, to be sure, any lack of wild speculation. A handful of
                freaked-out intellectuals is busy reading the tea leaves of a
                naturalistic version of posthumanism, only to give, at what they
                suppose to be a time-wall, one more spin -
                <q>hypermodernity</q> against <q>hypermorality</q> -
                to the all-too-familiar motives of a very <a href="#bib-habermas_future_2003">German ideology</a>.
                </p>
        </blockquote>
        <p>
        The big problem is once again anthropomorphization. Let's say with
        Sharkey, that <q>Like other cultural myths, it can be harmless in
            casual conversations in the lab. But it is a perilous road to follow in
            legal and political discussions about enabling machines to apply lethal
            force.</q> [<a href="#bib-sharkey_evitability_2012">Sharkey, 2012</a>, p. 791]
        I've already shown some cases where a military equipment was treated
        more like fellow comrades. Add another: <q>The <em>Washington
                Post</em> reported that soldiers on the battlefield using bomb disposal
            robots often treat them as fellow warriors and are sometimes prepared to
            risk their own lives to save them. They even take them fishing during
            leisure time and get them to hold a fishing rod in their gripper.</q>
        [<a href="#bib-sharkey_evitability_2012">Sharkey, 2012</a>, p. 792] or human-like
        discourse soaking to highest ranks of U. S. military
        <q>Gordon Johnson, former head of the Joint Forces Command at the
            Pentagon, told the <em>New York Times</em> that robots <q>don't get
                hungry. They're not afraid. They don't forget their orders. They don't
                care if the guy next to them has just been shot.</q></q> (Ibid). Robot
        is taken for soldier here and treated as such. Even if we admit that
        there will be human-like AI, we're not there yet and these
        <q>soldiers</q> are simple machines with no free will. I would quote
        Sharkey's once again as he brightly summarizes the problem which emerges
        here:
        </p>
        <div class="blockquote">
                <p>
                This is not just being picky about semantics. Anthropomorphic terms
                like <q>ethical</q> and <q>humane</q>, when applied to machines,
                lead us to making more and more false attribution about robots
                further down the line. They act as linguistic Trojan horses that
                smuggle in a rich interconnected web of human concepts that are not
                part of a computer system or how it operates. Once the reader has
                accepted a seemingly innocent Trojan term, such as using
                <q>humane</q> to describe a robot, it opens the gates to other
                meanings associated with the natural language use of the term that
                may have little or no intrinsic validity to what the computer
                program actually does. [<a href="#bib-sharkey_evitability_2012">Sharkey, 2012</a>, p. 793]
                </p>
        </div>
        <p>
        Direct result of such subversion, is responsibility slowly virtually
        shifting to machines. Man who is driving drone feels no more full
        responsibility for its actions, as drone is semi-autonomous. This
        quality of anthropomorphization effect is on the second side exploited
        in business and in therapy. Human-like robots are better sold [<a href="#bib-robertson_robo_2007">Robertson,
            2007</a>, <a href="#bib-larson_artificial_2010">Larson, 2010</a>] or they can be used as companions
        for e. g. elderly people [<a href="#bib-hakli_sociable_2014">Hakli et al.,
            2014</a>, <a href="#bib-kerstin_social_2014">Kerstin, 2014</a>,
        <a href="#bib-kernaghan_rights_2014">Kernaghan, 2014</a>,
        <a href="#bib-pfeifer_challenges_2012">Pfeifer et al., 2012</a>].
        The question of trust to AIs is repainted as <q><a href="#bib-michael_how_2014">commitment</a></q>.
        This targeted use makes border between what we pretend and what we
        believe even more fluid.
        </p>
        <p>
        Generally there is a technicist discussion if and how is AI able to
        <a href="#bib-evans_singularity_2007">destroy mankind</a>. Second part of it is AI will
        have intention to do it. <q>The concern is that the machines will
            view us as an unpredictable and dangerous species.</q> [<a href="#bib-panda_top_2015">Panda
            et al., 2015</a>, p. 111] shows typical
        argumentation. On the other side transhumanists and scientists are
        trying to oppose such fears [<a href="#bib-kurzweil_promise_2001">Kurzweil, 2001</a>]. Compared to
        direct destruction there is an eternal idea of society decay in the
        realm <a href="#bib-rossano_artificial_2001">where everything is provided</a>.
        </p>
        <p>
        Part of securitization discussion is also topic of AI as a citizen.
        We've already covered it in other chapters, so just adjusting some
        topics how they are reflected from this point. At first capability of AI
        to be a citizen is not coupled with its human status. There are
        tendencies to define new criteria and redefine traditional Turing test
        to <q><a href="#bib-erden_turing_2012">citizenship test</a></q>.
        Such activities can cast some light on how
        this duality humanity-citizenship is treated in today's society. Here is
        sometimes seen tendency to evade such problem by <q>&hellip;best not
            to make AIs extremely human-like in appearance, to avoid erroneous
            attributions that may blur the bright lines we set around moral
            categories (Arneson 1999). If such confusion were to develop, given the
            strong human tendency to anthropomorphize, we might encounter rising
            social pressure to give robots civil and political rights, as an
            extrapolation of the universal consistency that has proven so central to
            ameliorating the human condition.</q> [<a href="#bib-yampolskiy_safety_2013">Yampolskiy and Fox,
            2013</a>, p. 224] If scientist are not willing to
        give AIs civil rights, they are not against lending them at least some
        <q>non-harming</q> rights like <a href="#bib-davies_evolutionary_2011">intellectual property rights</a>. Of course, there is still discussion running if it is not
        possible to grant them more rights (with hidden goal to provide them
        also political rights, but <a href="#bib-kunneman_genomics_2013"><q>somehow</q> limited</a>).
        </p>

        <h2 id="auto-21"><a id="sec:art"></a>5 Story of Art </h2>
<div class="quote">
        I was looking at a collection of ancient machines that had no meaning: all syntax, no semantics. I was claiming I saw a meaning in it. But this meaning had no reality, outside of my mind. I had brought it into the hall with me, carrying it in my head, and now I was playing games with semantics by pasting it onto these iron monuments.
<div class="author"><a href="#bib-stephenson_anathem_2008">Neal Stephenson</a></div>
</div>

        <p>
        Art is quite disconnected from discussion of scientific and public
        circles. It is just <q>an art</q>. Nevertheless, it is exactly this
        sphere and especially sci-fi what builds public image and also motivates
        directions of scientific research. Topic of <q>scientific</q> AI is
        facing whole post-descartian epoch. From mentioned Frankenstein, R. U. R. through whole storm of books and movies from fifties and sixties.
        Exactly from the time when AI seemed to be almost here. Cold war also
        had its impact here. Partial deprivation during <q>AI winter</q><sup><a id="footnote-25-back" href="#footnote-25">25</a></sup>
        was fully replaced after its end on the dawn of singularitarianism. Not
        only literature but also big Hollywood theme with flagship
        <em>A. I.</em>
        by <a href="#bib-spielberg_.i._2001">Steven Spielberg</a>. Topic changing reflects contemporary state of science in some
        proportions. On the other side art is involved in topics which are not
        so changed from twenties, so almost a hundred years of possibility of
        <a href="#bib-asada_development_2015">emotionality</a>, <a href="#bib-berrar_turing_2013">creativity</a>, <a href="#bib-todoroi_creativitys_2012"><q>living</q> together</a> and what humanity means in such context [<a href="#bib-simon_futures_2013">Simon, 2013</a>,
        <a href="#bib-van_den_eede_where_2015">Van Den Eede, 2015</a>]. Classical leitmotif is <q>AI more human than humans</q>. Practically
        every story from previous chapters is here, religious utopias, Turing
        test and hesitations about salvation.
        </p>
        <p>
        As artistic forms are part of another field (while I was mainly focusing
        to scientific and public discourse) and plays by different rules
        [<a
        href="#bib-bourdieu_rules_1996">Bourdieu, 1996</a>] I will only point out few of specific aspects
        where science and religion meets art. <q>Science fiction (SF) novels
        frequently express religious themes and do the work of traditional
        religion; as a result, they are actors within the religious landscape.
        Although in many ways science fiction can oppose traditional religion,
        which often appears in SF as dogmatic, obscurantist, or even evil, the
        genre explores religious themes, and even gives them pride of
        place.</q> [<a href="#bib-geraci_novel_2014">Geraci, 2014</a>, p. 418] I
        would add to this, that not only religious actors but also scientific
        ones. Nevertheless, their religious aspect in light of preceding
        chapters is most relevant here.
        </p>
        <p>
        Apocalyptic AI is typical example of what is running through literary
        field. This concept is here from the beginning. <em><a href="#bib-shelley_frankenstein;_2012">Frankenstein</a></em>
        contains it in its primitive form as one
        destructive being. Twentieth century sees AIs operating on much larger
        scale of destruction especially with dawn of second world war.
        <em><a href="#bib-capek_r.u.r._2004">R. U. R.</a></em> is running the expansion &mdash; humanity is destroyed by AIs
        which shows to be at least same human as their creators. Trend is set
        and in epos <em><a href="#bib-herbert_dune_1965">Dune</a></em> written by two
        generations (1965&ndash;2007) of Herberts, AI is the ultimate enemy of
        mankind. Fear of it is presented three years later (1968) in Kubrick's
        blockbuster <em><a href="#bib-kubrick_2001:_1968">2001: A Space Odyssey</a></em>.
        1978 gives a birth to <em><a href="#bib-larson_battlestar_1978">Battlestar Galactica</a></em> (BSG) which starts at the moment when AI destroyed the mankind. 1990
        story reemerges in Simmons' <em><a href="#bib-simmons_hyperion_2011">Cantos Hyperion</a></em> &mdash; mankind is once more confronted with its eternal
        enemy. 1999 brings <em><a href="#bib-wachowski_matrix_1999">The Matrix</a></em> trilogy 1999&ndash;2003 where revolt against AI-imposed slavery ends
        also with cooperation of AIs and humans [<a href="#bib-diaz-diocaretz_matrix_2006">D&iacute;az-Diocaretz
            and Herbrechter, 2006</a>]. When it seems, that it is closed forever,
        war on terror resurrects <a href="#bib-larson_battlestar_2005">Battlestar Galactica</a> in 2004 and movies like
         <em><a href="#bib-pfister_transcendence_2014">Transcendence</a></em> where
          AI threat reappears. Story is mostly the same for whole
        hundred years &mdash; AI is an enemy but has some potentiality to merge
        with mankind (typically by desire for emotion and creativity) and
        transcend its flaws. Practically every piece mentioned here ends with
        this message more or less perpetrated by Christian topics. Starting with
        <em>R. U. R.</em>
        where final episode of <q>Adam and Eve</q> is explicit same as in
        <em>BSG</em>, which is based on Mormonism and whole episodes are devoted
        to problems of One God and return of Christ through <em>Cantos
            Hyperion</em> dealing at least with Abraham's sacrifice dilemma. Theory
        that AI threat topic is correlated with moments of ontological or
        physical insecurity of western society would be worth of some serious
        research.
        </p>
        <p>
        As typical Christian example is taken <em><a href="#bib-cameron_terminator_1984">Terminator</a></em> movie (and especially TV) series which is overloaded by
        Christian symbolic. Bennet points to mankind saviour John Connor (aka
        Jesus Christ) through terminators as AI angels and Sarah &mdash; the
        Virgin Mary. This concept is not unconscious, as authors reflects it:
        <q>&hellip;actor Thomas Dekker (John Connor) asks showrunner Josh
            Friedman why there is <q>so much Jesus</q> in the show and the latter
            replies, <q>The Terminator is a very religious series. [&hellip;] I liked the idea of exploring it in a
            non-obnoxious way</q></q> [<a href="#bib-bennett_deus_2014">Bennett, 2014</a>]
        </p>
        <p>
        Another repeated topic is relation of human to AI &mdash; what is the
        difference and who is more <q>human</q>. <em>Frankenstein</em> already
        hit the topic in similar way as <em>R. U. R.</em>.
        Classical piece is Dick's <em><a href="#bib-dick_androids_1996">Do Androids Dream of Electric Sheep?</a></em>
        1968 where variant of Turing test is used to
        determine if one is an android and as such should be <q>retired</q>.
        Main character is trapped in dilemma of murder/<q>retirement</q>. Book
        was later remade by Ridley Scott to similarly famous movie <em><a href="#bib-scott_blade_1982">Blade
            Runner</a></em> 1982. Two years later in 1984
        William Gibson starts new sc-fi movement cyberpunk via novel
        <em><a href="#bib-gibson_neuromancer_2000">Neuromancer</a></em> where AIs are more
        independent and thrive for their own independence and goals. Religious
        topics are made explicit in rest of the trilogy (<em><a href="#bib-gibson_count_1987">Count Zero</a></em>
        1984 and <em><a href="#bib-gibson_mona_2012">Mona Lisa Overdrive</a></em> 1988)
         where AIs take the role of network
        demigods. Topic is revisited in movies <em><a href="#bib-spielberg_.i._2001">A. I.</a></em>
        (analyzed e. g.
        in [<a href="#bib-chira_about_2014">Chira, 2014</a>]) or <em><a href="#bib-garland_ex_2015">Ex Machina</a></em> 2015. There is no theme of merging with humans, but more about
        co-existence. Symbiotic variant is also present in Iain M. Banks
        <q>Culture series</q> which also lead to some proposals about how AI
        can sustainably <a href="#bib-rumpala_artificial_2012">impact society</a>.
        </p>
        <p>
        Transhumanism strikes the sci-fi explicitly with <q>Cyberpunk 2.0</q>
        movement. Notable works like Stross' <em><a href="#bib-stross_accelerando_2015">Accelerando</a></em> in 2005 or Doctorow's <em><a href="#bib-doctorow_down_2015">Down and Out in the Magic
            Kingdom</a></em> are taking AI, Singularity
        and transhumanist future for granted in Kurzweil's vision of it.
        Functions as successful disseminators of positive image of transhumanism
        and as <a href="#bib-geraci_there_2011">tools for overcoming AI fears</a>].
        </p>
        <p>
        As computer engineers are quite tied to these topics and transhumanism
        at all, it is not a surprise, that with advent of computer games there
        is a prevalence of AI-related topics. <em>System Shock</em> in 1994
        introduces typical villain AI, which reappears in small intervals in
        <em>Deus Ex</em> 2000 or <em>Mass Effect</em> 2007 which typically don't
        impose new ideas and reiterate themes previously opened in literature.
        </p>
        <p>
        Whole art train is passing the scientific and transhumanism ideas to
        more general public and on the other side reifies legitimacy and driving
        force on side of scientists [<a href="#bib-geraci_novel_2014">Geraci, 2014</a>, <a href="#bib-geraci_robots_2007">Geraci,
            2007</a>, <a href="#bib-geraci_there_2011">Geraci, 2011</a>]. I've already mentioned this
        chapter is simplified as there is much more material which can (and
        should be) dealt with.
        </p>
        <h1 id="auto-22">3 Conclusion </h1>
        <p>
        AI anthropomorphization theme has shown as quite wide. It is permeating
        AI science itself but other &mdash; on first sight unrelated &mdash;
        fields like ethics, religion or law. All these <q>independent</q> and
        <q>rational</q> areas seems to be more or less affected by unconscious
        choices given the agency of things. It is nothing new, but worth to
        study on concrete examples. Difficulty of holistic dealing with the
        topic is on the other side seen also in the structure of work. It is not
        easy to talk about AI religion without touching its alchemistic side or
        looking to limits of programming. What can be taken as a lesson here is
        that potential empiric research should take in game all these effects.
        Otherwise, it may will describe some facets of the topic, but probably
        it will create distorted image. AI is not clear hard science. AI is
        human project as most others and is influenced by and influences living
        world also in purely social ways.
        </p>
        <p>
        Originally I have selected five narratives from whose only two are now
        present in text. I have dropped religious, alchemist and art stories due
        to lack of space. I have also investigated them and these chapters are
        available from me on demand. The selected ones are still broad enough to
        show different aspects which can be studied from sociological point of
        view.
        </p>
        <p>
        Story of Science has shown, that AI is not deliberate concept which is
        valid in any rational space. It was constructed especially in western
        civilization during last few hundred years and it has shown that in
        other intellectual and socio-political situation such concept need not
        exist at all.
        </p>
        <p>
        Story of Securitization on the other side shows that when such concept
        exists it can be on one side used as a political weapon nevertheless
        what real impact is. Or on the other side in combination with
        anthropomorphization it leads to weird human behaviour and laws which
        merely reflects <q>the objective reality</q>. Agency of things itself
        can modify how judge will decide its case as we have seen.
        </p>
        <p>
        When we would dive to religious stories, we would have seen that AI
        science field is driven by western Christianity and even non-consciously
        embracing eschatological discourse. This is something which on one side
        has big impact to securitization story and on the other side warns us a
        lot. As AI scientists would never say they are religious believers in
        AI, they behave like their followers. We can think about us as
        sociologists if we don't behave in same way with some other deity.
        </p>
        <p>
        Also many questions were opened to be tested by rigorous hypothesis,
        some of them can be verified by experiments, some by deeper field
        research. Anthropomorphic AI can seduce us to thinking about it as only
        a small fragment of sociology of science. But from other stories we see,
        that it is not only sociology of science, but also sociology of
        religion, sociology of things, &hellip; Sociology is also not the only
        tool which can be used to understand it &mdash; anthropology can give us
        a helpful hand with its tradition of observation. What we also need is
        independent point of view which can reflect on role of possible
        sociology of sociology of AI (in same meaning as meta-sociology of
        science or so-called <a href="#bib-muller_second-order_2014">second-order science</a>).
         So let's explore the borders of constructed science.
        </p>

        <h2 id="auto-23">Bibliography</h2>
        <div class="compact-block" style="text-indent: 0em">

                <dl>
                    <dt>
                        <strong>[lar, 1978]</strong>
                    </dt>
                    <dd>
                        <a id="bib-larson_battlestar_1978"></a>(1978). Battlestar Galactica. IMDB ID: tt0076984 IMDB
                        Rating: 7.1 (9,523 votes).
                    </dd>
                    <dt>
                        <strong>[lar, 2005]</strong>
                    </dt>
                    <dd>
                        <a id="bib-larson_battlestar_2005"></a>(2005). Battlestar Galactica. IMDB ID: tt0407362 IMDB
                        Rating: 8.8 (112,137 votes).
                    </dd>
                    <dt>
                        <strong>[Adam, 1998]</strong>
                    </dt>
                    <dd>
                        <a id="bib-adam_artificial_1998"></a>Adam, A. (1998). <i>Artificial Knowing: Gender and
                            the Thinking Machine</i>. Routledge, London ; New York.
                    </dd>
                    <dt>
                        <strong>[Adam, 2008]</strong>
                    </dt>
                    <dd>
                        <a id="bib-adam_ethics_2008"></a>Adam, A. (2008). Ethics for things. <i>Ethics &amp;
                            Information Technology</i>, 10(2/3):149.
                    </dd>
                    <dt>
                        <strong>[Alexander, 1989]</strong>
                    </dt>
                    <dd>
                        <a id="bib-alexander_structure_1989"></a>Alexander, J. C. (1989). <i>Structure and meaning :
                            relinking classical sociology</i>. New York : Columbia
                        University Press, c1989.
                    </dd>
                    <dt>
                        <strong>[Alexander, 2004]</strong>
                    </dt>
                    <dd>
                        <a id="bib-alexander_cultural_2004"></a>Alexander, J. C. (2004). Cultural Pragmatics: Social
                        Performance between Ritual and Strategy. <i>Sociological
                            Theory</i>, 22(4):527.
                    </dd>
                    <dt>
                        <strong>[Allen et al., 2000]</strong>
                    </dt>
                    <dd>
                        <a id="bib-allen_prolegomena_2000"></a>Allen, C., Varner, G., and Zinser, J. (2000).
                        Prolegomena to any future artificial moral agent. <i>Journal of
                            Experimental &amp; Theoretical Artificial Intelligence</i>,
                        12(3):251&ndash;261.
                    </dd>
                    <dt>
                        <strong>[Anderson and Anderson, 2007]</strong>
                    </dt>
                    <dd>
                        <a id="bib-anderson_status_2007"></a>Anderson, M. and Anderson, S. L. (2007). The status
                        of machine ethics: a report from the AAAI Symposium. <i>Minds
                            &amp; Machines</i>, 17(1):1&ndash;10.
                    </dd>
                    <dt>
                        <strong>[Asada, 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-asada_development_2015"></a>Asada, M. (2015). Development of artificial empathy.
                        <i>Neuroscience Research</i>, 90:41&ndash;50.
                    </dd>
                    <dt>
                        <strong>[Ashrafian, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-ashrafian_artificial_2014"></a>Ashrafian, H. (2014). Artificial Intelligence and
                        Robot Responsibilities: Innovating Beyond Rights. <i>Science and
                            Engineering Ethics</i>.
                    </dd>
                    <dt>
                        <strong>[Ashrafian, 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-ashrafian_aionai:_2015"></a>Ashrafian, H. (2015). AIonAI: A Humanitarian Law of
                        Artificial Intelligence and Robotics. <i>Science &amp;
                            Engineering Ethics</i>, 21(1):29&ndash;40.
                    </dd>
                    <dt>
                        <strong>[Asimov, 1977]</strong>
                    </dt>
                    <dd>
                        <a id="bib-asimov_i_1977"></a>Asimov, I. (1977). <i>I, Robot</i>. Fawcett Crest,
                        New York.
                    </dd>
                    <dt>
                        <strong>[Aupers, 2002]</strong>
                    </dt>
                    <dd>
                        <a id="bib-aupers_revenge_2002"></a>Aupers, S. (2002). The Revenge of the Machines: On
                        Modernity, Digital Technology and Animism. <i>Asian Journal of
                            Social Science</i>, 30(2):199&ndash;220.
                    </dd>
                    <dt>
                        <strong>[Aupers, 2010]</strong>
                    </dt>
                    <dd>
                        <a id="bib-aupers_where_2010"></a>Aupers, S. (2010). <q>Where the zeroes meet the ones</q>:
                        exploring the affinity between magic and computer technology. In
                        <i>Religions of modernity: relocating the sacred to the self and
                            the digital</i>, pages 219&ndash;238. Brill, Leiden.
                    </dd>
                    <dt>
                        <strong>[Bailey, 1998]</strong>
                    </dt>
                    <dd>
                        <a id="bib-bailey_implicit_1998"></a>Bailey, E. (1998). <i>Implicit religion : an
                            introduction</i>. London : Middlesex University, 1998.
                    </dd>
                    <dt>
                        <strong>[Barandiaran and Egbert, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-barandiaran_norm-establishing_2014"></a>Barandiaran, X. E. and Egbert, M. D. (2014).
                        Norm-establishing and norm-following in autonomous agency.
                        <i>Artificial Life</i>, 20(1):5&ndash;28.
                    </dd>
                    <dt>
                        <strong>[Bedau et al., 2000]</strong>
                    </dt>
                    <dd>
                        <a id="bib-bedau_open_2000"></a>Bedau, M. A., McCaskill, J. S., Packard, N. H.,
                        Rasmussen, S., Adami, C., Green, D. G., Ikegami, T., Kaneko, K.,
                        and Ray, T. S. (2000). Open problems in artificial life.
                        <i>Artificial Life</i>, 6(4):363&ndash;376.
                    </dd>
                    <dt>
                        <strong>[Bennett, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-bennett_deus_2014"></a>Bennett, E. (2014). Deus ex Machina: AI
                        Apocalypticism in Terminator: The Sarah Connor Chronicles.
                        <i>Journal of Popular Television</i>, 2(1):3&ndash;19.
                    </dd>
                    <dt>
                        <strong>[Berrar et al., 2013]</strong>
                    </dt>
                    <dd>
                        <a id="bib-berrar_turing_2013"></a>Berrar, D., Konagaya, A., and Schuster, A. (2013).
                        Turing Test Considered Mostly Harmless. <i>New Generation
                            Computing</i>, 31(4):241&ndash;263.
                    </dd>
                    <dt>
                        <strong>[Bibel, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-bibel_artificial_2014"></a>Bibel, W. (2014). Artificial Intelligence in a
                        historical perspective. <i>AI Communications</i>,
                        27(1):87&ndash;102.
                    </dd>
                    <dt>
                        <strong>[Bickhard, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-bickhard_robot_2014"></a>Bickhard, R. (2014). Robot Sociality: Genuine or
                        Simulation. In <i>Sociable Robots and the Future of Social
                            Relations : Proceedings of Robo-Philosophy 2014</i>, Frontiers
                        in Artificial Intelligence and Applications. IOS Press,
                        Amsterdam.
                    </dd>
                    <dt>
                        <strong>[Blank, 2013]</strong>
                    </dt>
                    <dd>
                        <a id="bib-blank_intervention_2013"></a>Blank, R. H. (2013). <i>Intervention in the Brain :
                            Politics, Policy, and Ethics</i>. Basic Bioethics. MIT Press,
                        Cambridge, Mass.
                    </dd>
                    <dt>
                        <strong>[Bobrow, 1964]</strong>
                    </dt>
                    <dd>
                        <a id="bib-bobrow_natural_1964"></a>Bobrow, D. G. (1964). <i>Natural Language Input for a
                            Computer Problem Solving System</i>. Doctoral Thesis,
                        Massachusetts Institute of Technology.
                    </dd>
                    <dt>
                        <strong>[Bonnefon et al., 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-bonnefon_autonomous_2015"></a>Bonnefon, J.-F., Shariff, A., and Rahwan, I. (2015).
                        Autonomous Vehicles Need Experimental Ethics: Are We Ready for
                        Utilitarian Cars? <i>arXiv:1510.03346 [cs]</i>. arXiv:
                        1510.03346.
                    </dd>
                    <dt>
                        <strong>[Bostrom, 1998]</strong>
                    </dt>
                    <dd>
                        <a id="bib-bostrom_how_1998"></a>Bostrom, N. (1998). How long before
                        superintelligence? <i>International Journal of Futures
                            Studies</i>, 1998(2).
                    </dd>
                    <dt>
                        <strong>[Bourdieu, 1984]</strong>
                    </dt>
                    <dd>
                        <a id="bib-bourdieu_distinction:_1984"></a>Bourdieu, P. (1984). <i>Distinction: A Social
                            Critiques of the Judgment of Taste</i>. Harvard University
                        Press, Cambridge.
                    </dd>
                    <dt>
                        <strong>[Bourdieu, 1996]</strong>
                    </dt>
                    <dd>
                        <a id="bib-bourdieu_rules_1996"></a>Bourdieu, P. (1996). <i>The Rules of Art: Genesis and
                            Structure of the Literary Field</i>. Stanford University Press.
                    </dd>
                    <dt>
                        <strong>[Brouwer and Heyting, 1980]</strong>
                    </dt>
                    <dd>
                        <a id="bib-brouwer_collected_1980"></a>Brouwer, L. E. J. and Heyting, A. (1980).
                        <i>Collected works. 1, 1,</i>. North-Holland Publishing Company,
                        Amsterdam [etc.].
                    </dd>
                    <dt>
                        <strong>[Buzan et al., 1998]</strong>
                    </dt>
                    <dd>
                        <a id="bib-buzan_security:_1998"></a>Buzan, B., W&aelig;ver, O., and Wilde, J. d. (1998).
                        <i>Security: a new framework for analysis</i>. Lynne Rienner
                        Pub, Boulder, Colo.
                    </dd>
                    <dt>
                        <strong>[Cameron, 1984]</strong>
                    </dt>
                    <dd>
                        <a id="bib-cameron_terminator_1984"></a>Cameron, J. (1984). The Terminator. IMDB ID:
                        tt0088247 IMDB Rating: 8.1 (547,982 votes).
                    </dd>
                    <dt>
                        <strong>[Campa, 2008]</strong>
                    </dt>
                    <dd>
                        <a id="bib-campa_pure_2008"></a>Campa, R. (2008). Pure Science and the Posthuman
                        Future. <i>Journal of Evolution &amp; Technology</i>,
                        19(1):1&ndash;7.
                    </dd>
                    <dt>
                        <strong>[&#x010C;apek, 2004]</strong>
                    </dt>
                    <dd>
                        <a id="bib-capek_r.u.r._2004"></a>&#x010C;apek, K. (2004). <i>R.U.R.</i>
                    </dd>
                    <dt>
                        <strong>[&#x010C;erka et al., 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-cerka_liability_2015"></a>&#x010C;erka, P., Grigiene, J., and Sirbikyte, G.
                        (2015). Liability for damages caused by artificial intelligence.
                        <i>Computer Law &amp; Security Review: The International Journal
                            of Technology Law and Practice</i>.
                    </dd>
                    <dt>
                        <strong>[Chira, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-chira_about_2014"></a>Chira, R.-G. (2014). About SF and Fantasy through
                        Artificial Intelligence. <i>Caietele Echinox</i>,
                        26:345&ndash;359.
                    </dd>
                    <dt>
                        <strong>[Chomsky, 2002]</strong>
                    </dt>
                    <dd>
                        <a id="bib-chomsky_syntactic_2002"></a>Chomsky, N. (2002). <i>Syntactic Structures</i>.
                        Walter de Gruyter.
                    </dd>
                    <dt>
                        <strong>[Churchland, 2001]</strong>
                    </dt>
                    <dd>
                        <a id="bib-churchland_matter_2001"></a>Churchland, P. M. (2001). <i>Matter and consciousness
                            : a contemporary introduction to the philosophy of mind</i>.
                        Bradford book. Cambridge, Mass. : MIT Press, 2001.
                    </dd>
                    <dt>
                        <strong>[Clay, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-clay_transhumanism_2012"></a>Clay, E. (2012). Transhumanism and the Orthodox
                        Christian Tradition. In <i>Building Better Humans? : Refocusing
                            the Debate on Transhumanism</i>, Beyond Humanism: Trans- and
                        Posthumanism. Peter Lang, Frankfort au Main.
                    </dd>
                    <dt>
                        <strong>[Coeckelbergh, 2009]</strong>
                    </dt>
                    <dd>
                        <a id="bib-coeckelbergh_virtual_2009"></a>Coeckelbergh, M. (2009). Virtual moral agency,
                        virtual moral responsibility: on the moral significance of the
                        appearance, perception, and performance of artificial agents.
                        <i>AI &amp; Society</i>, 24(2):181&ndash;189.
                    </dd>
                    <dt>
                        <strong>[Coeckelbergh, 2013]</strong>
                    </dt>
                    <dd>
                        <a id="bib-coeckelbergh_pervasion_2013"></a>Coeckelbergh, M. (2013). Pervasion of what?
                        Techno-human ecologies and their ubiquitous spirits. <i>AI &amp;
                            Society</i>, 28(1):55&ndash;63.
                    </dd>
                    <dt>
                        <strong>[Cole et al., 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-cole_automated_2012"></a>Cole, R. J., Bild, A., and Matheus, E. (2012).
                        Automated and human intelligence: direct and indirect
                        consequences. <i>Intelligent Buildings International</i>,
                        4(1):4&ndash;14.
                    </dd>
                    <dt>
                        <strong>[Cole-Turner, 2011]</strong>
                    </dt>
                    <dd>
                        <a id="bib-cole-turner_transhumanism_2011"></a>Cole-Turner, R. (2011). <i>Transhumanism and
                            transcendence Christian hope in an age of technological
                            enhancement</i>. Georgetown University Press, Washington, DC.
                    </dd>
                    <dt>
                        <strong>[Cristianini, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-cristianini_current_2014"></a>Cristianini, N. (2014). On the current paradigm in
                        artificial intelligence. <i>AI Communications</i>,
                        27(1):37&ndash;43.
                    </dd>
                    <dt>
                        <strong>[Cullen, 2008]</strong>
                    </dt>
                    <dd>
                        <a id="bib-cullen_three_2008"></a>Cullen, J. (2008). The Three Minds Argument.
                        <i>Journal of Evolution &amp; Technology</i>, 20(1):51&ndash;60.
                    </dd>
                    <dt>
                        <strong>[Davies, 2011]</strong>
                    </dt>
                    <dd>
                        <a id="bib-davies_evolutionary_2011"></a>Davies, C. R. (2011). An evolutionary step in
                        intellectual property rights &ndash; Artificial intelligence and
                        intellectual property. <i>Computer Law and Security Review: The
                            International Journal of Technology and Practice</i>,
                        27:601&ndash;619.
                    </dd>
                    <dt>
                        <strong>[Davis, 1998]</strong>
                    </dt>
                    <dd>
                        <a id="bib-davis_techgnosis:_1998"></a>Davis, E. (1998). <i>Techgnosis: myth, magic and
                            mysticism in the age of information</i>. Harmony Bks, New York.
                    </dd>
                    <dt>
                        <strong>[Davis, 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-davis_ethical_2015"></a>Davis, E. (2015). Ethical guidelines for a
                        superintelligence. <i>Artificial Intelligence</i>,
                        220:121&ndash;124.
                    </dd>
                    <dt>
                        <strong>[de Beer, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-de_beer_responsibility_2012"></a>de Beer, F. (2012). Responsibility in the age of the
                        new media: Are cyborgs responsible beings? <i>Communicatio:
                            South African Journal for Communication Theory &amp;
                            Research</i>, 38(1):15.
                    </dd>
                    <dt>
                        <strong>[de Chardin, 1966]</strong>
                    </dt>
                    <dd>
                        <a id="bib-de_chardin_mans_1966"></a>de Chardin, T. (1966). <i>Man's Place in Nature: The
                            Human Zoological Group</i>. Collins, London, fontana books
                        edition.
                    </dd>
                    <dt>
                        <strong>[DeBaets, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-debaets_can_2014"></a>DeBaets, A. M. (2014). Can a Robot Pursue the Good?
                        Exploring Artificial Moral Agency. <i>Journal of Evolution &amp;
                            Technology</i>, 24(3):76&ndash;86.
                    </dd>
                    <dt>
                        <strong>[Dennett, 1992]</strong>
                    </dt>
                    <dd>
                        <a id="bib-dennett_consciousness_1992"></a>Dennett, D. C. (1992). <i>Consciousness
                            explained</i>. Allen Lane The Penguin Press, London.
                    </dd>
                    <dt>
                        <strong>[Dick, 1996]</strong>
                    </dt>
                    <dd>
                        <a id="bib-dick_androids_1996"></a>Dick, P. K. (1996). <i>Do androids dream of electric
                            sheep?</i> Ballantine Books, New York.
                    </dd>
                    <dt>
                        <strong>[Doctorow, 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-doctorow_down_2015"></a>Doctorow, C. (2015). <i>Down and Out in the Magic
                            Kingdom</i>. Booklassic.
                    </dd>
                    <dt>
                        <strong>[Dodig Crnkovic and &Ccedil;&uuml;r&uuml;kl&uuml;, 2012]
                        </strong>
                    </dt>
                    <dd>
                        <a id="bib-dodig_crnkovic_robots:_2012"></a>Dodig Crnkovic, G. and &Ccedil;&uuml;r&uuml;kl&uuml;,
                        B. (2012). Robots: ethical by design. <i>Ethics &amp;
                            Information Technology</i>, 14(1):61.
                    </dd>
                    <dt>
                        <strong>[Dupuy and DeBevoise, 2013]</strong>
                    </dt>
                    <dd>
                        <a id="bib-dupuy_mark_2013"></a>Dupuy, J. P. and DeBevoise, M. B. (2013). <i>The Mark
                            of the Sacred</i>. Cultural Memory in the Present. Stanford
                        University Press, Stanford, California.
                    </dd>
                    <dt>
                        <strong>[D&iacute;az-Diocaretz and Herbrechter, 2006]</strong>
                    </dt>
                    <dd>
                        <a id="bib-diaz-diocaretz_matrix_2006"></a>D&iacute;az-Diocaretz, M. and Herbrechter, S. (2006).
                        <i>The Matrix in Theory</i>. Critical Studies. Brill Academic
                        Publishers, Amsterdam.
                    </dd>
                    <dt>
                        <strong>[Eco, 1995]</strong>
                    </dt>
                    <dd>
                        <a id="bib-eco_search_1995"></a>Eco, U. (1995). <i>The Search for the Perfect
                            Language</i>. Wiley.
                    </dd>
                    <dt>
                        <strong>[Englert et al., 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-englert_logical_2014"></a>Englert, M., Siebert, S., and Ziegler, M. (2014).
                        Logical Limitations to Machine Ethics with Consequences to
                        Lethal Autonomous Weapons.
                    </dd>
                    <dt>
                        <strong>[EPSRC, 2010]</strong>
                    </dt>
                    <dd>
                        <a id="bib-epsrc_principles_2010"></a>EPSRC (2010). Principles of robotics - EPSRC website.
                    </dd>
                    <dt>
                        <strong>[Erden and Rainey, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-erden_turing_2012"></a>Erden, Y. J. and Rainey, S. (2012). Turing and the
                        Real Girl. <i>New Bioethics</i>, 18(2):133&ndash;144.
                    </dd>
                    <dt>
                        <strong>[Evans, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-evans_faith_2014"></a>Evans, J. H. (2014). Faith in science in global
                        perspective: Implications for transhumanism. <i>Public
                            Understanding of Science</i>, 23(7):814.
                    </dd>
                    <dt>
                        <strong>[Evans, 2007]</strong>
                    </dt>
                    <dd>
                        <a id="bib-evans_singularity_2007"></a>Evans, W. (2007). Singularity Warfare: A Bibliometric
                        Survey of Militarized Transhumanism. <i>Journal of Evolution
                            &amp; Technology</i>, 16(1):161&ndash;165.
                    </dd>
                    <dt>
                        <strong>[Fern&aacute;ndez Castro, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-fernandez_castro_shaping_2014"></a>Fern&aacute;ndez Castro, V. (2014). <i>Shaping
                            robotic minds</i>, volume 273 of <i>Frontiers in Artificial
                            Intelligence and Applications</i>. IOS Press. 71.
                    </dd>
                    <dt>
                        <strong>[Field, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-field_south_2012"></a>Field, C. (2012). South Korean Robot Ethics Charter
                        2012.
                    </dd>
                    <dt>
                        <strong>[Floridi, 2004]</strong>
                    </dt>
                    <dd>
                        <a id="bib-floridi_open_2004"></a>Floridi, L. (2004). Open Problems in the Philosophy
                        of Information. <i>Metaphilosophy</i>, 35(4):554&ndash;582.
                    </dd>
                    <dt>
                        <strong>[Floridi and Sanders, 2004]</strong>
                    </dt>
                    <dd>
                        <a id="bib-floridi_morality_2004"></a>Floridi, L. and Sanders, J. (2004). On the Morality
                        of Artificial Agents. <i>Minds &amp; Machines</i>,
                        14(3):349&ndash;379.
                    </dd>
                    <dt>
                        <strong>[Fuller, 2009]</strong>
                    </dt>
                    <dd>
                        <a id="bib-fuller_knowledge_2009"></a>Fuller, S. (2009). Knowledge politics and new
                        converging technologies: a social epistemological perspective.
                        <i>Innovation: The European Journal of Social Sciences</i>,
                        22(1):7&ndash;34.
                    </dd>
                    <dt>
                        <strong>[Garland, 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-garland_ex_2015"></a>Garland, A. (2015). Ex Machina.
                    </dd>
                    <dt>
                        <strong>[Garner, 2011]</strong>
                    </dt>
                    <dd>
                        <a id="bib-garner_theology_2011"></a>Garner, S. (2011). <i>Theology and the Body :
                            Reflections on Being Flesh and Blood</i>. Interface: a Forum for
                        Theology in the World. ATF Theology, Hindmarsh, SA.
                    </dd>
                    <dt>
                        <strong>[Geraci, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-geraci_novel_2014"></a>Geraci, R. (2014). A Novel Society: Science Fiction
                        Novels as Religious Actors. <i>Implicit Religion</i>,
                        17(4):417&ndash;431.
                    </dd>
                    <dt>
                        <strong>[Geraci, 2007]</strong>
                    </dt>
                    <dd>
                        <a id="bib-geraci_robots_2007"></a>Geraci, R. M. (2007). Robots and the Sacred in
                        Science and Science Fiction: Theological Implications of
                        Artificial Intelligence. <i>Zygon: Journal of Religion &amp;
                            Science</i>, 42(4):961&ndash;980.
                    </dd>
                    <dt>
                        <strong>[Geraci, 2008]</strong>
                    </dt>
                    <dd>
                        <a id="bib-geraci_apocalyptic_2008"></a>Geraci, R. M. (2008). Apocalyptic AI: religion and
                        the promise of artificial intelligence. <i>Journal of the
                            American Academy of Religion</i>, 76(1):138&ndash;166.
                    </dd>
                    <dt>
                        <strong>[Geraci, 2011]</strong>
                    </dt>
                    <dd>
                        <a id="bib-geraci_there_2011"></a>Geraci, R. M. (2011). There and back again:
                        transhumanist evangelism in science fiction and popular science.
                        <i>Implicit Religion</i>, 14(2):141&ndash;172.
                    </dd>
                    <dt>
                        <strong>[Gibson, 1987]</strong>
                    </dt>
                    <dd>
                        <a id="bib-gibson_count_1987"></a>Gibson, W. (1987). <i>Count Zero</i>. Penguin.
                    </dd>
                    <dt>
                        <strong>[Gibson, 2000]</strong>
                    </dt>
                    <dd>
                        <a id="bib-gibson_neuromancer_2000"></a>Gibson, W. (2000). <i>Neuromancer</i>. Penguin.
                    </dd>
                    <dt>
                        <strong>[Gibson, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-gibson_mona_2012"></a>Gibson, W. (2012). <i>Mona Lisa Overdrive</i>. Random
                        House Publishing Group.
                    </dd>
                    <dt>
                        <strong>[Gilbert and Forney, 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-gilbert_can_2015"></a>Gilbert, R. L. and Forney, A. (2015). Can avatars
                        pass the Turing test? Intelligent agent perception in a 3d
                        virtual environment. <i>International Journal of Human-Computer
                            Studies</i>, 73:30&ndash;36.
                    </dd>
                    <dt>
                        <strong>[Gladden, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-gladden_social_2014"></a>Gladden, 2 ), M. . . (2014). <i>The social robot as
                            <q>charismatic leader</q>: A phenomenology of human submission to
                        nonhuman power</i>, volume 273 of <i>Frontiers in Artificial
                        Intelligence and Applications</i>. IOS Press. 329.
                    </dd>
                    <dt>
                        <strong>[Goodey and Dawson Books, 2011]</strong>
                    </dt>
                    <dd>
                        <a id="bib-goodey_history_2011"></a>Goodey, C. F. and Dawson Books (2011). <i>A History
                            of Intelligence and <q>intellectual Disability</q> : The Shaping of
                        Psychology in Early Modern Europe</i>. Ashgate Publishing Ltd,
                    Burlington, VT.
                    </dd>
                    <dt>
                        <strong>[Gozzi Jr., 1994]</strong>
                    </dt>
                    <dd>
                        <a id="bib-gozzi_jr._note_1994"></a>Gozzi Jr., R. (1994). A Note on the Metaphorically
                        Charged Discourse of Early Artificial Intelligence. <i>Metaphor
                            &amp; Symbolic Activity</i>, 9(3):233.
                    </dd>
                    <dt>
                        <strong>[Greer, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-greer_is_2014"></a>Greer, K. (2014). Is Intelligence Artificial?
                        <i>arXiv:1403.1076 [cs]</i>. arXiv: 1403.1076.
                    </dd>
                    <dt>
                        <strong>[Haan, 2013]</strong>
                    </dt>
                    <dd>
                        <a id="bib-haan_i_2013"></a>Haan, M. N. d. (2013). <i>I am a Cyborg: Identity,
                            Peripheral Reflexivity and Transhumanism</i>. Master, Utrecht
                        University.
                    </dd>
                    <dt>
                        <strong>[Habermas, 2003]</strong>
                    </dt>
                    <dd>
                        <a id="bib-habermas_future_2003"></a>Habermas, J. (2003). <i>The future of human
                            nature</i>. Cambridge : Polity Press, 2003.
                    </dd>
                    <dt>
                        <strong>[Habermas and Cronin, 2008]</strong>
                    </dt>
                    <dd>
                        <a id="bib-habermas_between_2008"></a>Habermas, J. and Cronin, C. (2008). <i>Between
                            naturalism and religion : philosophical essays</i>. Cambridge :
                        Polity, c2008.
                    </dd>
                    <dt>
                        <strong>[Habermas and Outhwaite, 1996]</strong>
                    </dt>
                    <dd>
                        <a id="bib-habermas_habermas_1996"></a>Habermas, J. and Outhwaite, W. (1996). <i>The
                            Habermas Reader</i>. Polity Press.
                    </dd>
                    <dt>
                        <strong>[Hakli et al., 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-hakli_sociable_2014"></a>Hakli, R., N&oslash;rskov, M., and Seibt, J. (2014).
                        <i>Sociable Robots and the Future of Social Relations :
                            Proceedings of Robo-Philosophy 2014</i>. Frontiers in Artificial
                        Intelligence and Applications. IOS Press, Amsterdam.
                    </dd>
                    <dt>
                        <strong>[Hallevy, 2013]</strong>
                    </dt>
                    <dd>
                        <a id="bib-hallevy_when_2013"></a>Hallevy, G. (2013). <i>When Robots Kill : Artificial
                            Intelligence Under Criminal Law</i>. Northeastern University
                        Press, Boston.
                    </dd>
                    <dt>
                        <strong>[Herbert, 1965]</strong>
                    </dt>
                    <dd>
                        <a id="bib-herbert_dune_1965"></a>Herbert, F. (1965). <i>Dune</i>. Ace Books.
                    </dd>
                    <dt>
                        <strong>[Herzfeld, 2002]</strong>
                    </dt>
                    <dd>
                        <a id="bib-herzfeld_creating_2002"></a>Herzfeld, N. (2002). Creating in our own image:
                        artificial intelligence and the image of God. <i>Zygon</i>,
                        37(2):303&ndash;316.
                    </dd>
                    <dt>
                        <strong>[Herzfeld, 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-herzfeld_empathetic_2015"></a>Herzfeld, N. (2015). Empathetic Computers: The
                        Problem of Confusing Persons and Things. <i>Dialog: A Journal of
                            Theology</i>, 54(1):34&ndash;39.
                    </dd>
                    <dt>
                        <strong>[Hodder, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-hodder_entangled:_2012"></a>Hodder, I. (2012). <i>Entangled: An Archaeology of
                            the Relationships Between Humans and Things</i>. John Wiley
                        &amp; Sons.
                    </dd>
                    <dt>
                        <strong>[Houtman and Aupers, 2010]</strong>
                    </dt>
                    <dd>
                        <a id="bib-houtman_religions_2010"></a>Houtman, D. and Aupers, S. (2010). <i>Religions of
                            Modernity : Relocating the Sacred to the Self and the
                            Digital</i>. International Studies in Religion and Society.
                        Brill, Leiden.
                    </dd>
                    <dt>
                        <strong>[Hri&#x015F;c&#x0103;, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-hrisca_artificial_2012"></a>Hri&#x015F;c&#x0103;, A. M. (2012). Artificial Body:
                        Between <q>to Be</q> and <q>to Have</q>. <i>Studia
                            Universitatis Babes-Bolyai, Philosophia</i>,
                        57(2):121&ndash;135.
                    </dd>
                    <dt>
                        <strong>[Hughes, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-hughes_politics_2012"></a>Hughes, J. (2012). The politics of transhumanism and
                        the techno-millennial imagination, 1626-2030. <i>Zygon</i>,
                        47(4):757&ndash;776. 757.
                    </dd>
                    <dt>
                        <strong>[Jones, 2003]</strong>
                    </dt>
                    <dd>
                        <a id="bib-jones_resolving_2003"></a>Jones, S. (2003). Resolving classical experience and
                        the quantum world. <i>Technoetic Arts: A Journal of Speculative
                            Research</i>, 1(2):143&ndash;164.
                    </dd>
                    <dt>
                        <strong>[Kaur, 2013]</strong>
                    </dt>
                    <dd>
                        <a id="bib-kaur_kant_2013"></a>Kaur, G. D. (2013). Kant and the simulation
                        hypothesis. <i>AI &amp; SOCIETY</i>, 30(2):183&ndash;192.
                    </dd>
                    <dt>
                        <strong>[Kernaghan, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-kernaghan_rights_2014"></a>Kernaghan, K. (2014). The rights and wrongs of
                        robotics: Ethics and robots in public organizations. <i>Canadian
                            Public Administration</i>, 57(4):485&ndash;506.
                    </dd>
                    <dt>
                        <strong>[Kerstin, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-kerstin_social_2014"></a>Kerstin, D. (2014). Social Robots As Companions:
                        Challenges and Opportunities. <i>Frontiers in Artificial
                            Intelligence and Applications</i>, pages 9&ndash;10.
                    </dd>
                    <dt>
                        <strong>[Khalil, 1993]</strong>
                    </dt>
                    <dd>
                        <a id="bib-khalil_artificial_1993"></a>Khalil, O. E. M. (1993). Artificial Decision-Making
                        and Artificial Ethics: A Management Concern. <i>Journal of
                            Business Ethics</i>, 12(4):313&ndash;321.
                    </dd>
                    <dt>
                        <strong>[Kim and Kim, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-kim_humanoid_2012"></a>Kim, M.-S. and Kim, E.-J. (2012). Humanoid robots as
                        <q>The Cultural Other</q>: are we able to love our
                        creations? <i>AI &amp; SOCIETY</i>, 28(3):309&ndash;318.
                    </dd>
                    <dt>
                        <strong>[Kleene, 1952]</strong>
                    </dt>
                    <dd>
                        <a id="bib-kleene_introduction_1952"></a>Kleene, S. C. (1952). <i>Introduction to
                            metamathematics.</i> Van Nostrand, New York.
                    </dd>
                    <dt>
                        <strong>[Knight and Murphy, 2010]</strong>
                    </dt>
                    <dd>
                        <a id="bib-knight_human_2010"></a>Knight, C. C. and Murphy, N. C. (2010). <i>Human
                            Identity at the Intersection of Science, Technology and
                            Religion</i>. Ashgate Science and Religion Series. Ashgate
                        Publishing Ltd, Farnham, Surrey, England.
                    </dd>
                    <dt>
                        <strong>[Koosed, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-koosed_bible_2014"></a>Koosed, J. L. (2014). <i>The Bible and
                            Posthumanism</i>. Society of Biblical Literature. Semeia
                        Studies. Society of Biblical Literature, Atlanta.
                    </dd>
                    <dt>
                        <strong>[Kubrick, 1968]</strong>
                    </dt>
                    <dd>
                        <a id="bib-kubrick_2001:_1968"></a>Kubrick, S. (1968). 2001: A Space Odyssey. IMDB ID:
                        tt0062622 IMDB Rating: 8.3 (387,129 votes).
                    </dd>
                    <dt>
                        <strong>[Kunneman and Derkx, 2013]</strong>
                    </dt>
                    <dd>
                        <a id="bib-kunneman_genomics_2013"></a>Kunneman, H. and Derkx, P. (2013). <i>Genomics and
                            Democracy : Towards a <q>lingua Democratica</q> for the Public Debate
                        on Genomics</i>. Life Sciences, Ethics and Democracy. Brill
                    Academic Publishers, Amsterdam.
                    </dd>
                    <dt>
                        <strong>[Kurzweil, 2001]</strong>
                    </dt>
                    <dd>
                        <a id="bib-kurzweil_promise_2001"></a>Kurzweil, R. (2001). Promise and Peril &ndash; The
                        Deeply Intertwined Poles of 21st Century Technology.
                        <i>Communications of the ACM</i>, 44(3):88&ndash;91.
                    </dd>
                    <dt>
                        <strong>[Kurzweil, 2005]</strong>
                    </dt>
                    <dd>
                        <a id="bib-kurzweil_singularity_2005"></a>Kurzweil, R. (2005). <i>The Singularity Is Near: When
                            Humans Transcend Biology</i>. Penguin.
                    </dd>
                    <dt>
                        <strong>[Kurzweil, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-kurzweil_dont_2014"></a>Kurzweil, R. (2014). Don't Fear Artificial
                        Intelligence. <i>Time</i>, 184(26/27):28&ndash;28.
                    </dd>
                    <dt>
                        <strong>[Larson, 2010]</strong>
                    </dt>
                    <dd>
                        <a id="bib-larson_artificial_2010"></a>Larson, D. A. (2010). Artificial Intelligence:
                        Robots, Avatars, and the Demise of the Human Mediator. <i>Ohio
                            State Journal on Dispute Resolution</i>, 25(1):105&ndash;163.
                    </dd>
                    <dt>
                        <strong>[Latour, 2007]</strong>
                    </dt>
                    <dd>
                        <a id="bib-latour_reassembling_2007"></a>Latour, B. (2007). <i>Reassembling the Social: An
                            Introduction to Actor-Network-Theory</i>. OUP Oxford.
                    </dd>
                    <dt>
                        <strong>[Latour and Porter, 1991]</strong>
                    </dt>
                    <dd>
                        <a id="bib-latour_we_1991"></a>Latour, B. and Porter, C. (1991). <i>We have never
                            been modern</i>. Cambridge, Mass. : Harvard University Press,
                        c1991.
                    </dd>
                    <dt>
                        <strong>[Laufer, 2013]</strong>
                    </dt>
                    <dd>
                        <a id="bib-laufer_artificial_2013"></a>Laufer, M. S. (2013). Artificial Intelligence in
                        Humans.
                    </dd>
                    <dt>
                        <strong>[Laukyte, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-laukyte_artificial_2014"></a>Laukyte, M. (2014). <i>Artificial agents: Some
                            consequences of a few capacities</i>, volume 273 of <i>Frontiers
                            in Artificial Intelligence and Applications</i>. IOS Press. 115.
                    </dd>
                    <dt>
                        <strong>[Leuenberger, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-leuenberger_universal_2014"></a>Leuenberger, G. (2014). Universal Algorithmic Ethics.
                        <i>arXiv:1404.1718 [cs]</i>. arXiv: 1404.1718.
                    </dd>
                    <dt>
                        <strong>[Levine, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-levine_sociality_2014"></a>Levine, A. (2014). Sociality Without Prior
                        Individuality. In <i>Sociable Robots and the Future of Social
                            Relations : Proceedings of Robo-Philosophy 2014</i>, Frontiers
                        in Artificial Intelligence and Applications. IOS Press,
                        Amsterdam.
                    </dd>
                    <dt>
                        <strong>[Levinson, 2003]</strong>
                    </dt>
                    <dd>
                        <a id="bib-levinson_ethical_2003"></a>Levinson, S. E. (2003). Ethical implications of an
                        experiment in artificial intelligence. <i>World Englishes</i>,
                        22(3):227&ndash;232.
                    </dd>
                    <dt>
                        <strong>[Lin et al., 2011]</strong>
                    </dt>
                    <dd>
                        <a id="bib-lin_robot_2011"></a>Lin, P., Abney, K., and Bekey, G. (2011). Robot
                        ethics: Mapping the issues for a mechanized world. <i>Artificial
                            Intelligence</i>, 175(5&ndash;6):942&ndash;949.
                    </dd>
                    <dt>
                        <strong>[MacCormack, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-maccormack_posthuman_2012"></a>MacCormack, P. (2012). <i>Posthuman Ethics :
                            Embodiment and Cultural Theory</i>. Ashgate Publishing Ltd,
                        Burlington, VT.
                    </dd>
                    <dt>
                        <strong>[Mahootian, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-mahootian_ideals_2012"></a>Mahootian, F. (2012). Ideals of Human Perfection: A
                        Comparison of Sufism and Transhumanism. In <i>Building Better
                            Humans? : Refocusing the Debate on Transhumanism</i>, Beyond
                        Humanism: Trans- and Posthumanism. Peter Lang, Frankfort au
                        Main.
                    </dd>
                    <dt>
                        <strong>[Marchetti-Bowick, 2009]</strong>
                    </dt>
                    <dd>
                        <a id="bib-marchetti-bowick_is_2009"></a>Marchetti-Bowick, M. (2009). Is Your Roomba Male or
                        Female? The Role of Gender Stereotypes and Cultural Norms in
                        Robot Design. <i>Intersect: The Stanford Journal of Science,
                            Technology and Society</i>, 2(1):90&ndash;103.
                    </dd>
                    <dt>
                        <strong>[McIntosh, 2010]</strong>
                    </dt>
                    <dd>
                        <a id="bib-mcintosh_transhuman_2010"></a>McIntosh, D. (2010). The Transhuman Security Dilemma.
                        <i>Journal of Evolution &amp; Technology</i>, 21(2):32&ndash;48.
                    </dd>
                    <dt>
                        <strong>[Megill, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-megill_emotion_2014"></a>Megill, J. (2014). Emotion, Cognition and Artificial
                        Intelligence. <i>Minds &amp; Machines</i>, 24(2):189&ndash;199.
                    </dd>
                    <dt>
                        <strong>[Mehlman and Project Muse, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-mehlman_transhumanist_2012"></a>Mehlman, M. J. and Project Muse (2012).
                        <i>Transhumanist Dreams and Dystopian Nightmares : The Promise
                            and Peril of Genetic Engineering</i>. UPCC Book Collections on
                        Project MUSE. Johns Hopkins University Press, Baltimore.
                    </dd>
                    <dt>
                        <strong>[Menabrea, 1842]</strong>
                    </dt>
                    <dd>
                        <a id="bib-menabrea_sketch_1842"></a>Menabrea, L. F. (1842). Sketch of The Analytical
                        Engine.
                    </dd>
                    <dt>
                        <strong>[Mercer, 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-mercer_bodies_2015"></a>Mercer, C. (2015). Bodies and Persons: Theological
                        Reflections on Transhumanism. <i>Dialog: A Journal of
                            Theology</i>, 54(1):27&ndash;33.
                    </dd>
                    <dt>
                        <strong>[Merton, 1973]</strong>
                    </dt>
                    <dd>
                        <a id="bib-merton_sociology_1973"></a>Merton, R. K. (1973). <i>The Sociology of Science:
                            Theoretical and Empirical Investigations</i>. University of
                        Chicago Press.
                    </dd>
                    <dt>
                        <strong>[Michael and Salice, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-michael_how_2014"></a>Michael, J. . . . and Salice, A. . . . (2014).
                        <i>(How) Can robots make commitments? A pragmatic approach</i>,
                        volume 273 of <i>Frontiers in Artificial Intelligence and
                            Applications</i>. IOS Press. 125.
                    </dd>
                    <dt>
                        <strong>[Minsky and Papert, 1972]</strong>
                    </dt>
                    <dd>
                        <a id="bib-minsky_perceptrons:_1972"></a>Minsky, M. L. and Papert, S. A. (1972).
                        <i>Perceptrons: an introduction to computational geometry</i>.
                        The MIT Press, Cambridge/Mass., 2. print. with corr edition.
                    </dd>
                    <dt>
                        <strong>[Moravec, 1988]</strong>
                    </dt>
                    <dd>
                        <a id="bib-moravec_mind_1988"></a>Moravec, H. (1988). <i>Mind Children: The Future of
                            Robot and Human Intelligence</i>. Harvard University Press.
                    </dd>
                    <dt>
                        <strong>[Moravec, 1991]</strong>
                    </dt>
                    <dd>
                        <a id="bib-moravec_universal_1991"></a>Moravec, H. (1991). The Universal Robot.
                    </dd>
                    <dt>
                        <strong>[Mossman and Tirosh-Samuelson, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-mossman_building_2012"></a>Mossman, K. L. and Tirosh-Samuelson, H. (2012).
                        <i>Building Better Humans? : Refocusing the Debate on
                            Transhumanism</i>. Beyond Humanism: Trans- and Posthumanism.
                        Peter Lang, Frankfort au Main.
                    </dd>
                    <dt>
                        <strong>[Muggleton, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-muggleton_alan_2014"></a>Muggleton, S. (2014). Alan Turing and the development
                        of Artificial Intelligence. <i>AI Communications</i>,
                        27(1):3&ndash;10.
                    </dd>
                    <dt>
                        <strong>[Mul, 2010]</strong>
                    </dt>
                    <dd>
                        <a id="bib-mul_cyberspace_2010"></a>Mul, J. d. (2010). <i>Cyberspace Odyssey : Towards a
                            Virtual Ontology and Anthropology</i>. Cambridge Scholars,
                        Newcastle upon Tyne.
                    </dd>
                    <dt>
                        <strong>[M&uuml;ller and Riegler, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-muller_second-order_2014"></a>M&uuml;ller, K. H. and Riegler, A. (2014).
                        Second-Order Science: A Vast and Largely Unexplored Science
                        Frontier. <i>Constructivist Foundations</i>, 10(1):7&ndash;15.
                    </dd>
                    <dt>
                        <strong>[Newton, 1723]</strong>
                    </dt>
                    <dd>
                        <a id="bib-newton_philosophiae_1723"></a>Newton, Sir, I. (1723). <i>Philosophiae naturalis
                            principia mathematica</i>. Amsterodam : Sumptibus societatis,
                        1723.
                    </dd>
                    <dt>
                        <strong>[Nina Lester and Gabriel, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-nina_lester_discursive_2014"></a>Nina Lester, J. and Gabriel, R. (2014). The
                        discursive construction of intelligence in introductory
                        educational psychology textbooks. <i>Discourse Studies</i>,
                        16(6):776.
                    </dd>
                    <dt>
                        <strong>[Owaied, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-owaied_new_2012"></a>Owaied, H. H. (2012). New Overview of Artificial
                        Intelligence. <i>International Journal of Academic Research</i>,
                        4(2):181&ndash;185.
                    </dd>
                    <dt>
                        <strong>[Panda et al., 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-panda_top_2015"></a>Panda, S. S., Panda, M., Das, R. R., and Mohanty, P.
                        K. (2015). The top species will no longer be humans: Robotic
                        surgery could be a problem. <i>Journal of Minimal Access
                            Surgery</i>, 11(1):111&ndash;111.
                    </dd>
                    <dt>
                        <strong>[Pfeifer et al., 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-pfeifer_challenges_2012"></a>Pfeifer, R., Lungarella, M., and Iida, F. (2012). The
                        Challenges Ahead for Bio-Inspired <q>Soft</q> Robotics.
                    <i>Communications of the ACM</i>, 55(11):76&ndash;87.
                    </dd>
                    <dt>
                        <strong>[Pfister, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-pfister_transcendence_2014"></a>Pfister, W. (2014). Transcendence. IMDB ID: tt2209764
                        IMDB Rating: 6.3 (156,718 votes).
                    </dd>
                    <dt>
                        <strong>[Pratt, 1987]</strong>
                    </dt>
                    <dd>
                        <a id="bib-pratt_thinking_1987"></a>Pratt, V. (1987). <i>Thinking machines: the evolution
                            of artificial intelligence</i>. B. Blackwell.
                    </dd>
                    <dt>
                        <strong>[Raatikainen, 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-raatikainen_gos_2015"></a>Raatikainen, P. (2015). G&ouml;del's Incompleteness
                        Theorems. In Zalta, E. N., editor, <i>The Stanford Encyclopedia
                            of Philosophy</i>. Stanford University, spring 2015 edition.
                    </dd>
                    <dt>
                        <strong>[Rescher, 2011]</strong>
                    </dt>
                    <dd>
                        <a id="bib-rescher_philosophical_2011"></a>Rescher, N. (2011). <i>Philosophical Episodes</i>.
                        Walter de Gruyter.
                    </dd>
                    <dt>
                        <strong>[Robertson, 2007]</strong>
                    </dt>
                    <dd>
                        <a id="bib-robertson_robo_2007"></a>Robertson, J. (2007). Robo sapiens Japanicus:
                        Humanoid robots and the posthuman family. <i>Critical Asian
                            Studies</i>, 39(3):369&ndash;398. 369.
                    </dd>
                    <dt>
                        <strong>[RoboLaw, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-robolaw_guidelines_2014"></a>RoboLaw (2014). Guidelines on Regulating Robotics.
                    </dd>
                    <dt>
                        <strong>[Rodr&iacute;guez et al., 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-rodriguez_meaning_2012"></a>Rodr&iacute;guez, D., Hermosillo, J., and Lara, B.
                        (2012). Meaning in Artificial Agents: The Symbol Grounding
                        Problem Revisited. <i>Minds &amp; Machines</i>,
                        22(1):25&ndash;34.
                    </dd>
                    <dt>
                        <strong>[Rosental, 2003]</strong>
                    </dt>
                    <dd>
                        <a id="bib-rosental_certifying_2003"></a>Rosental, C. (2003). Certifying Knowledge: The
                        Sociology of a Logical Theorem in Artificial Intelligence.
                        <i>American Sociological Review</i>, 68(4):623&ndash;644.
                    </dd>
                    <dt>
                        <strong>[Rossano, 2001]</strong>
                    </dt>
                    <dd>
                        <a id="bib-rossano_artificial_2001"></a>Rossano, M. J. (2001). Artificial intelligence,
                        religion, and community concern. <i>Zygon</i>,
                        36(1):57&ndash;75.
                    </dd>
                    <dt>
                        <strong>[Rumpala, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-rumpala_artificial_2012"></a>Rumpala, Y. (2012). Artificial intelligences and
                        political organization: An exploration based on the science
                        fiction work of Iain M. Banks. <i>Technology in Society</i>,
                        34:23&ndash;32.
                    </dd>
                    <dt>
                        <strong>[Samuelson and Tirosh-Samuelson, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-samuelson_jewish_2012"></a>Samuelson, N. and Tirosh-Samuelson, H. (2012). Jewish
                        Perspectives on Transhumanism. In <i>Building Better Humans? :
                            Refocusing the Debate on Transhumanism</i>, Beyond Humanism:
                        Trans- and Posthumanism. Peter Lang, Frankfort au Main.
                    </dd>
                    <dt>
                        <strong>[Schiaffonati, 2003]</strong>
                    </dt>
                    <dd>
                        <a id="bib-schiaffonati_framework_2003"></a>Schiaffonati, V. (2003). A Framework for the
                        Foundation of the Philosophy of Artificial Intelligence.
                        <i>Minds &amp; Machines</i>, 13(4):537&ndash;552.
                    </dd>
                    <dt>
                        <strong>[Schopenhauer, 2008]</strong>
                    </dt>
                    <dd>
                        <a id="bib-schopenhauer_studies_2008"></a>Schopenhauer, A. (2008). <i>Studies in Pessimism, On
                            Human Nature, and Religion: a Dialogue, etc.</i> Digireads.com.
                    </dd>
                    <dt>
                        <strong>[Schwartz, 1989]</strong>
                    </dt>
                    <dd>
                        <a id="bib-schwartz_artificial_1989"></a>Schwartz, R. D. (1989). Artificial intelligence as a
                        sociological phenomenon. <i>Canadian Journal of Sociology</i>,
                        14(2):179.
                    </dd>
                    <dt>
                        <strong>[Scott, 1982]</strong>
                    </dt>
                    <dd>
                        <a id="bib-scott_blade_1982"></a>Scott, R. (1982). Blade Runner. IMDB ID: tt0083658
                        IMDB Rating: 8.2 (427,643 votes).
                    </dd>
                    <dt>
                        <strong>[Seaman and Rossler, 2008]</strong>
                    </dt>
                    <dd>
                        <a id="bib-seaman_neosentience_2008"></a>Seaman, B. and Rossler, O. (2008). Neosentience a new
                        branch of scientific and poetic inquiry related to artificial
                        intelligence. <i>Technoetic Arts: A Journal of Speculative
                            Research</i>, 6(1):31&ndash;40.
                    </dd>
                    <dt>
                        <strong>[Searle, 1980]</strong>
                    </dt>
                    <dd>
                        <a id="bib-searle_minds_1980"></a>Searle, J. (1980). Minds, Brains and Programs.
                        <i>Behavioral and Brain Sciences</i>, 1980(3).
                    </dd>
                    <dt>
                        <strong>[Sharkey and Sharkey, 2006]</strong>
                    </dt>
                    <dd>
                        <a id="bib-sharkey_artificial_2006"></a>Sharkey, N. and Sharkey, A. (2006). Artificial
                        intelligence and natural magic. <i>ARTIFICIAL INTELLIGENCE
                            REVIEW</i>, 25(1-2):9&ndash;19.
                    </dd>
                    <dt>
                        <strong>[Sharkey, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-sharkey_evitability_2012"></a>Sharkey, N. E. (2012). The evitability of autonomous
                        robot warfare. <i>International Review of the Red Cross</i>,
                        94(886):787&ndash;799.
                    </dd>
                    <dt>
                        <strong>[Shaw-Garlock, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-shaw-garlock_gendered_2014"></a>Shaw-Garlock, G. (2014). <i>Gendered by design:
                            Gender codes in social robotics</i>, volume 273 of <i>Frontiers
                            in Artificial Intelligence and Applications</i>. IOS Press. 309.
                    </dd>
                    <dt>
                        <strong>[Shelley, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-shelley_frankenstein;_2012"></a>Shelley, M. W. (2012). <i>Frankenstein; Or, The
                            Modern Prometheus</i>. Lackington, Hughes, Harding, Mavor &amp;
                        Jones, London.
                    </dd>
                    <dt>
                        <strong>[Sherwin, 2007]</strong>
                    </dt>
                    <dd>
                        <a id="bib-sherwin_golems_2007"></a>Sherwin, B. L. (2007). Golems in the Biotech Century.
                        <i>Zygon: Journal of Religion &amp; Science</i>,
                        42(1):133&ndash;143.
                    </dd>
                    <dt>
                        <strong>[Simmons, 2011]</strong>
                    </dt>
                    <dd>
                        <a id="bib-simmons_hyperion_2011"></a>Simmons, D. (2011). <i>Hyperion</i>. Random House
                        Publishing Group.
                    </dd>
                    <dt>
                        <strong>[Simon, 2013]</strong>
                    </dt>
                    <dd>
                        <a id="bib-simon_futures_2013"></a>Simon, R. (2013). The Futures of Humanity: Anarchism,
                        Technoscience, and the Sociology of God. <i>Contemporary
                            Sociology</i>, 42(5):726&ndash;732.
                    </dd>
                    <dt>
                        <strong>[Singer, 1975]</strong>
                    </dt>
                    <dd>
                        <a id="bib-singer_animal_1975"></a>Singer, P. (1975). <i>Animal liberation: a new ethics
                            for our treatment of animals</i>. New York review : distributed
                        by Random House.
                    </dd>
                    <dt>
                        <strong>[Skinner, 1976]</strong>
                    </dt>
                    <dd>
                        <a id="bib-skinner_about_1976"></a>Skinner, B. F. (1976). <i>About behaviorism</i>.
                        Vintage Books, New York.
                    </dd>
                    <dt>
                        <strong>[Sparrow, 2007]</strong>
                    </dt>
                    <dd>
                        <a id="bib-sparrow_killer_2007"></a>Sparrow, R. (2007). Killer Robots. <i>Journal of
                            Applied Philosophy</i>, 24(1):62&ndash;77.
                    </dd>
                    <dt>
                        <strong>[Spielberg, 2001]</strong>
                    </dt>
                    <dd>
                        <a id="bib-spielberg_.i._2001"></a>Spielberg, S. (2001). A.I. Artificial Intelligence.
                        IMDB ID: tt0212720 IMDB Rating: 7.1 (224,102 votes).
                    </dd>
                    <dt>
                        <strong>[Stannard, 2000]</strong>
                    </dt>
                    <dd>
                        <a id="bib-stannard_god_2000"></a>Stannard, R. (2000). <i>God For The 21St Century</i>.
                        Templeton Foundation Press.
                    </dd>
                    <dt>
                        <strong>[Stephenson, 2005]</strong>
                    </dt>
                    <dd>
                        <a id="bib-stephenson_system_2005"></a>Stephenson, N. (2005). <i>The system of the
                            world</i>. Harper Perennial, New York.
                    </dd>
                    <dt>
                        <strong>[Stephenson, 2008]</strong>
                    </dt>
                    <dd>
                        <a id="bib-stephenson_anathem_2008"></a>Stephenson, N. (2008). <i>Anathem</i>. William
                        Morrow, New York, NY, 1st ed edition.
                    </dd>
                    <dt>
                        <strong>[Stross, 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-stross_accelerando_2015"></a>Stross, C. (2015). <i>Accelerando</i>. Booklassic.
                    </dd>
                    <dt>
                        <strong>[Tamatea, 2010]</strong>
                    </dt>
                    <dd>
                        <a id="bib-tamatea_online_2010"></a>Tamatea, L. (2010). Online Buddhist and Christian
                        Responses to Artificial Intelligence. <i>Zygon: Journal of
                            Religion &amp; Science</i>, 45(4):979&ndash;1002.
                    </dd>
                    <dt>
                        <strong>[Tegmark, 2014]</strong>
                    </dt>
                    <dd>
                        <a id="bib-tegmark_friendly_2014"></a>Tegmark, M. (2014). Friendly Artificial Intelligence:
                        the Physics Challenge. <i>arXiv:1409.0813 [cs]</i>. arXiv:
                        1409.0813.
                    </dd>
                    <dt>
                        <strong>[Thagard, 2010]</strong>
                    </dt>
                    <dd>
                        <a id="bib-thagard_brain_2010"></a>Thagard, P. (2010). <i>The brain and the meaning of
                            life</i>. Princeton Univ. Press, Princeton, N.J.
                    </dd>
                    <dt>
                        <strong>[Tirosh-Samuelson, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-tirosh-samuelson_transhumanism_2012"></a>Tirosh-Samuelson, H. (2012). Transhumanism as a
                        Secularist Faith. <i>Zygon: Journal of Religion &amp;
                            Science</i>, 47(4):710&ndash;734.
                    </dd>
                    <dt>
                        <strong>[Todoroi, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-todoroi_creativitys_2012"></a>Todoroi, D. (2012). Creativity's Kernel Development
                        for Conscience Society. <i>Informatica Economica</i>,
                        16(1):70&ndash;86.
                    </dd>
                    <dt>
                        <strong>[Tonkens, 2009]</strong>
                    </dt>
                    <dd>
                        <a id="bib-tonkens_challenge_2009"></a>Tonkens, R. (2009). A Challenge for Machine Ethics.
                        <i>Minds &amp; Machines</i>, 19(3):421&ndash;438.
                    </dd>
                    <dt>
                        <strong>[Torrance, 2008]</strong>
                    </dt>
                    <dd>
                        <a id="bib-torrance_ethics_2008"></a>Torrance, S. (2008). Ethics and consciousness in
                        artificial agents. <i>AI &amp; Society</i>, 22(4):495&ndash;521.
                    </dd>
                    <dt>
                        <strong>[Torrance, 2013]</strong>
                    </dt>
                    <dd>
                        <a id="bib-torrance_artificial_2013"></a>Torrance, S. (2013). Artificial agents and the
                        expanding ethical circle. <i>AI and Society</i>,
                        28(4):399&ndash;414. 399.
                    </dd>
                    <dt>
                        <strong>[Turing, 1950]</strong>
                    </dt>
                    <dd>
                        <a id="bib-turing_computing_1950"></a>Turing, A. (1950). Computing Machinery and
                        Intelligence. <i>Mind</i>, 59(236):433&ndash;460.
                    </dd>
                    <dt>
                        <strong>[Turing, 1936]</strong>
                    </dt>
                    <dd>
                        <a id="bib-turing_computable_1936"></a>Turing, A. M. (1936). On computable numbers, with an
                        application to the Entscheidungsproblem. <i>J. of Math</i>,
                        58(345-363):5.
                    </dd>
                    <dt>
                        <strong>[Van Den Eede, 2015]</strong>
                    </dt>
                    <dd>
                        <a id="bib-van_den_eede_where_2015"></a>Van Den Eede, Y. (2015). Where Is the Human? Beyond
                        the Enhancement Debate. <i>Science, Technology &amp; Human
                            Values</i>, 40(1):149.
                    </dd>
                    <dt>
                        <strong>[Vargas et al., 2011]</strong>
                    </dt>
                    <dd>
                        <a id="bib-vargas_advocating_2011"></a>Vargas, P., Fernaeus, Y., Lim, M., Enz, S., Ho, W.,
                        Jacobsson, M., and Ayllet, R. (2011). Advocating an ethical
                        memory model for artificial companions from a human-centred
                        perspective. <i>AI &amp; Society</i>, 26(4):329&ndash;337.
                    </dd>
                    <dt>
                        <strong>[Velik, 2010]</strong>
                    </dt>
                    <dd>
                        <a id="bib-velik_quo_2010"></a>Velik, R. (2010). Quo vadis, Intelligent Machine?
                        <i>Quo vadis, Intelligente Machine?</i>, 1(4):13&ndash;22.
                    </dd>
                    <dt>
                        <strong>[Velik, 2012]</strong>
                    </dt>
                    <dd>
                        <a id="bib-velik_ai_2012"></a>Velik, R. (2012). AI Reloaded: Objectives,
                        Potentials, and Challenges of the Novel Field of Brain-Like
                        Artificial Intelligence. <i>BRAIN: Broad Research in Artificial
                            Intelligence &amp; Neuroscience</i>, 3(3):25&ndash;54.
                    </dd>
                    <dt>
                        <strong>[Verdoux, 2011]</strong>
                    </dt>
                    <dd>
                        <a id="bib-verdoux_emerging_2011"></a>Verdoux, P. (2011). Emerging Technologies and the
                        Future of Philosophy. <i>Metaphilosophy</i>,
                        42(5):682&ndash;707.
                    </dd>
                    <dt>
                        <strong>[Veruggio, 2007]</strong>
                    </dt>
                    <dd>
                        <a id="bib-veruggio_euron_2007"></a>Veruggio, G. (2007). EURON Roboethics Roadmap.
                    </dd>
                    <dt>
                        <strong>[Wachowski and Wachowski, 1999]</strong>
                    </dt>
                    <dd>
                        <a id="bib-wachowski_matrix_1999"></a>Wachowski, A. and Wachowski, L. (1999). The Matrix.
                        IMDB ID: tt0133093 IMDB Rating: 8.7 (1,107,718 votes).
                    </dd>
                    <dt>
                        <strong>[Wallach et al., 2007]</strong>
                    </dt>
                    <dd>
                        <a id="bib-wallach_machine_2007"></a>Wallach, W., Allen, C., and Smit, I. (2007). Machine
                        morality: bottom-up and top-down approaches for modelling human
                        moral faculties. <i>AI &amp; SOCIETY</i>, 22(4):565&ndash;582.
                    </dd>
                    <dt>
                        <strong>[Weizenbaum, 1966]</strong>
                    </dt>
                    <dd>
                        <a id="bib-weizenbaum_eliza--computer_1966"></a>Weizenbaum, J. (1966). ELIZA&ndash;A Computer Program
                        For the Study of Natural Language Communication Between Man And
                        Machine. <i>Communications of the ACM</i>, 9(1):36.
                    </dd>
                    <dt>
                        <strong>[Weizenbaum, 1976]</strong>
                    </dt>
                    <dd>
                        <a id="bib-weizenbaum_computer_1976"></a>Weizenbaum, J. (1976). <i>Computer power and human
                            reason: from judgment to calculation</i>. Freeman, San
                        Francisco.
                    </dd>
                    <dt>
                        <strong>[Whitehead and Russell, 1963]</strong>
                    </dt>
                    <dd>
                        <a id="bib-whitehead_principia_1963"></a>Whitehead, A. N. and Russell, B. (1963). <i>Principia
                            Mathematica Volume I</i>. Cambridge University Press, Cambridge,
                        2 edition.
                    </dd>
                    <dt>
                        <strong>[Wittgenstein, 1967]</strong>
                    </dt>
                    <dd>
                        <a id="bib-wittgenstein_zettel_1967"></a>Wittgenstein, L. (1967). <i>Zettel, 40th Anniversary
                            Edition</i>. University of California Press.
                    </dd>
                    <dt>
                        <strong>[Yampolskiy and Fox, 2013]</strong>
                    </dt>
                    <dd>
                        <a id="bib-yampolskiy_safety_2013"></a>Yampolskiy, R. and Fox, J. (2013). Safety Engineering
                        for Artificial General Intelligence. <i>Topoi</i>,
                        32(2):217&ndash;226. 217.
                    </dd>
                </dl>
        </div>
        <h2>Footnotes</h2>
        <a id="footnote-1"></a>
            <div class="footnote">
                1. I'm not going to dive into the deepness of math theory. It
                should be sufficient to know, that there <em>is</em> some
                reflection in math about what truth means. Intuitionism deals
                with concept of truth as with something what can be
                constructed and proved. Simply, the Truth is something what
                can be proved &mdash; Plato was wrong.
                If you are interested in the topic, start with [<a href="#bib-brouwer_collected_1980">Brouwer
                    and Heyting, 1980</a>].
                <a href="#footnote-1-back">Back</a>
            </div>
        <a id="footnote-2"></a>
            <div class="footnote">
                2. It would be worth to mention at least famous G&ouml;del's
                first incompleteness theorem which has immense impact on
                computing and related philosophies. Theorem states:
                <q>that in any consistent formal system <em>F</em>
                    within which a certain amount of arithmetic can be carried
                    out, there are statements of the language of <em>F</em>
                    which can neither be proved nor disproved in <em>F</em></q>
                [<a href="#bib-raatikainen_gos_2015">Raatikainen, 2015</a>].
                <a href="#footnote-2-back">Back</a>
            </div>
        <a id="footnote-3"></a>
            <div class="footnote">
                3. While Babbage was probably firm on his claim, that his
                machine can't think, we can find in texts related to
                <em>Analytical Engine</em> pattern of <q>starting</q>
                anthropomorphization. Even stating that <q>machine is not
                    a thinking being</q> [<a href="#bib-menabrea_sketch_1842">Menabrea, 1842</a>] is the
                point which have to be taken seriously in our quest.
                <a href="#footnote-3-back">Back</a>
            </div>
        <a id="footnote-4"></a>
            <div class="footnote">
                4. Oversimplified these all different concepts from
                mathematical constructivism says that what is computable is
                identical on some level  &mdash;
                languages, mathematical functions and what is ideal computer
                able to compute. It is often used to argue that human brain is
                on exactly same level and thus there is some limit of
                epistemology inherently included (I strip the
                embodiment/cognition problem here).
                <a href="#footnote-4-back">Back</a>
            </div>
        <a id="footnote-5"></a>
            <div class="footnote">
                5. Dartmouth Summer Research Project on Artifical Intelligence
                <a href="#footnote-5-back">Back</a>
            </div>
        <a id="footnote-6"></a>
            <div class="footnote">
                6. <em>Technological Singularity</em> is crucial term in
                strong-AI and transhumanism program. The point-of-no-return
                when humankind can no longer estimate future as it is defined
                by self-improving AIs themselves.
                <a href="#footnote-6-back">Back</a>
            </div>
        <a id="footnote-7"></a>
            <div class="footnote">
                7. italics in original
                <a href="#footnote-7-back">Back</a>
            </div>
        <a id="footnote-8"></a>
            <div class="footnote">
                8. There is whole field dealing with how this <q>truth</q> is
                established and how the field itself is defending its position
                against sociological introspection. One for all  &mdash;
                Rosental [<a href="#bib-rosental_certifying_2003">Rosental, 2003</a>] shows how even concept
                of <q>logic</q> is not only methodological tool, but also
                <q>privileged object that enables exploration of the
                    material and social forms of intellectual work, including the
                    building of credibility</q>. Its elaborated uses (which are
                studied only with big investment [<a href="#bib-latour_reassembling_2007">Latour, 2007</a>])
                can also be viewed as active tool of defense.
                <a href="#footnote-8-back">Back</a>
            </div>
        <a id="footnote-9"></a>
            <div class="footnote">
                9. There is also criticism to this [<a href="#bib-de_beer_responsibility_2012">de Beer,
                    2012</a>] and other approaches [<a href="#bib-schiaffonati_framework_2003">Schiaffonati,
                    2003</a>].
                <a href="#footnote-9-back">Back</a>
            </div>
        <a id="footnote-10"></a>
            <div class="footnote">
                10. As e. g. [<a href="#bib-yampolskiy_safety_2013">Yampolskiy and Fox,
                    2013</a>] notes, there most possible AIs according tu current
                state-of-the-art will be of non-anthropomorphic design.
                <a href="#footnote-10-back">Back</a>
            </div>
        <a id="footnote-11"></a>
            <div class="footnote">
                11. Of course except for AI fanatics. In [<a href="#bib-verdoux_emerging_2011">Verdoux,
                    2011</a>] is paraphrased Bostrom in way, that it makes no
                sense to design ethical behaviour for AI as it is better
                equipped than human to do so. Which is in this case
                interesting. Because I can hypothetize that not even
                materiality itself but also only potential vision of
                materiality (some future AI) has direct impact on society.
                Here we can see, that it removes shackles of responsibility
                from AI designers. According to Bostrom they shouldn't even
                think about what is and what is not ethically right, because
                there will be something better (I feel urge here to say
                <q>God-like</q>) what will outperform them.
                <a href="#footnote-11-back">Back</a>
            </div>
        <a id="footnote-12"></a>
            <div class="footnote">
                12. They still have problems when it comes to
                algorithmization. <q>Given the tremendous implications of
                    failure, the system must avoid not only bugs in its
                    construction, but also bugs introduced even after the design
                    is complete, whether via a random mutation caused by
                    deficiencies in hardware, or via a natural event such as a
                    short circuit modifying some component of the system.</q>
                [<a href="#bib-yampolskiy_safety_2013">Yampolskiy and Fox, 2013</a>, p. 222]
                This makes basic requirement of deontic system  &mdash;
                that agent will behave according to rules without exceptions
                technically impossible.
                <a href="#footnote-12-back">Back</a>
            </div>
        <a id="footnote-13"></a>
            <div class="footnote">
                13. Family of ethical problems, when actor is faced with
                problem to choose who has to be killed/harmed in situation
                when there is no win-win solution.
                <a href="#footnote-13-back">Back</a>
            </div>
        <a id="footnote-14"></a>
            <div class="footnote">
                14. italics from original
                <a href="#footnote-14-back">Back</a>
            </div>
        <a id="footnote-15"></a>
            <div class="footnote">
                15. <a href="http://prirucka.ujc.cas.cz/?slovo=robot">http://prirucka.ujc.cas.cz/?slovo=robot</a>
                <a href="#footnote-15-back">Back</a>
            </div>
        <a id="footnote-16"></a>
            <div class="footnote">
                16. <q>By a <q>superintelligence</q> we mean an intellect
                    that is much smarter than the best human brains in practically
                    every field, including scientific creativity, general wisdom
                    and social skills. This definition leaves open how the
                    superintelligence is implemented: it could be a digital
                    computer, an ensemble of networked computers, cultured
                    cortical tissue or what have you. It also leaves open whether
                    the superintelligence is conscious and has subjective
                    experiences.<br>Entities such as companies or the scientific
                    community are not superintelligences according to this
                    definition. Although they can perform a number of tasks of
                    which no individual human is capable, they are not intellects
                    and there are many fields in which they perform much worse
                    than a human brain  &mdash; for example,
                    you can't have real-time conversation with <q>the
                        scientific community</q>.</q> [<a href="#bib-bostrom_how_1998">Bostrom, 1998</a>]
                <a href="#footnote-16-back">Back</a>
            </div>
        <a id="footnote-17"></a>
            <div class="footnote">
                17. Long story short  &mdash; Computer
                dealing with Turing test is comparable to room with monkey
                behaving according to some algorithm, thus it is can't be
                intelligent. Logical mistake hidden in argument is presumption
                that human brain can't be simulated by such means &mdash; which is dogma for Searle. On the other
side it doesn't stop other AI scientists to <q>solve</q>
problem created by Searle and encode <q>understanding</q> as
another anthropomorphic feature into AI [<a href="#bib-rodriguez_meaning_2012">Rodr&iacute;guez
et al., 2012</a>].
                <a href="#footnote-17-back">Back</a>
            </div>
        <a id="footnote-18"></a>
            <div class="footnote">
                18. Transhumanism sometimes uses abbreviation <em>h<sup>+</sup></em>
                which directly refers to this concept by its minuscule
                <q>h</q> marking humanity as something underdeveloped which
                nevertheless can (and will be) transcended by transhuman
                <em><sup>+</sup></em> (<a href="http://humanityplus.org">http://humanityplus.org</a>).
                <a href="#footnote-18-back">Back</a>
            </div>
        <a id="footnote-19"></a>
            <div class="footnote">
                19. Other links to Bible can be found in [<a href="#bib-koosed_bible_2014">Koosed,
                    2014</a>].
                <a href="#footnote-19-back">Back</a>
            </div>
        <a id="footnote-20"></a>
            <div class="footnote">
                20. italics from original
                <a href="#footnote-20-back">Back</a>
            </div>
        <a id="footnote-21"></a>
            <div class="footnote">
                21. Mormon Transhumanist Association  &mdash;
                <a href="http://transfigurism.org">http://transfigurism.org</a>, Turing Church
                &mdash; <a href="http://turingchurch.com">http://turingchurch.com</a>
                <a href="#footnote-21-back">Back</a>
            </div>
        <a id="footnote-22"></a>
        <div class="footnote">
            22. italics added
            <a href="#footnote-22-back">Back</a>
        </div>
        <a id="footnote-23"></a>
        <div class="footnote">
            23. AI makes important part of emerging technologies military
            discourse [<a href="#bib-evans_singularity_2007">Evans, 2007</a>].
            <a href="#footnote-23-back">Back</a>
        </div>
        <a id="footnote-24"></a>
        <div class="footnote">
            24. Better known via movie adaptation <em>Blade Runner</em>
            [<a href="#bib-scott_blade_1982">Scott, 1982</a>]
            <a href="#footnote-24-back">Back</a>
        </div>
        <a id="footnote-25"></a>
        <div class="footnote">
            25. Period of rapid research slowing following Minsky's and
            Papert's proof of some basic neural network deficiency.
             [<a href="#bib-minsky_perceptrons:_1972">Minsky and Papert, 1972</a>]
            <a href="#footnote-25-back">Back</a>
        </div>
        </div>
    </body>
</html>
